[{"path":"/articles/Zelig.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Translating Zelig to clarify","text":"document, demonstrate common uses Zelig (Imai, King, Lau 2008) tasks can performed using clarify. ’ll include examples computing predictions representative values (.e., setx() sim() Zelig), rare-events logit model, estimating average treatment effect (ATT) matching, combining estimates multiple imputation. usual workflow Zelig fit model using zelig(), specify quantities interest simulate using setx() zelig() output, simulate quantities using sim(). clarify uses similar approach, except model fit outside clarify using functions different R package. addition, clarify’s sim_apply() allows computation arbitrary quantity interest. Unlike Zelig, clarify follows recommendations Rainey (2023) use estimates computed original model coefficients rather average simulated draws. ’ll demonstrate replicate standard Zelig analysis using clarify step--step. simulation-based inference involves randomness algorithms may perfectly align, one shouldn’t expect results identical, though cases, similar. Note Zelig clarify function called “sim()”, always make clear package’s sim() used.","code":"## library(\"Zelig\") library(\"clarify\") set.seed(100)"},{"path":"/articles/Zelig.html","id":"predictions-at-representative-values","dir":"Articles","previous_headings":"","what":"Predictions at representative values","title":"Translating Zelig to clarify","text":"’ll use lalonde dataset MatchIt fit linear model re78 function treatment treat covariates. ’ll interested predicted values outcome typical unit level treatment first difference.","code":"data(\"lalonde\", package = \"MatchIt\")"},{"path":"/articles/Zelig.html","id":"zelig-workflow","dir":"Articles","previous_headings":"Predictions at representative values","what":"Zelig workflow","title":"Translating Zelig to clarify","text":"Zelig, fit model using zelig(): Next, use setx() setx1() set values treat: Next simulate values using sim(): Finally, can print plot predicted values first differences:","code":"fit <- zelig(re78 ~ treat + age + educ + married + race +                nodegree + re74 + re75, data = lalonde,              model = \"ls\", cite = FALSE) fit <- setx(fit, treat = 0) fit <- setx1(fit, treat = 1) fit <- Zelig::sim(fit) fit plot(fit)"},{"path":"/articles/Zelig.html","id":"clarify-workflow","dir":"Articles","previous_headings":"Predictions at representative values","what":"clarify workflow","title":"Translating Zelig to clarify","text":"clarify, fit model using functions outside clarify, like stats::lm()fixest::feols(). Next, simulate model coefficients using clarify::sim(): Next, use sim_setx() set values predictors: Finally, can summarize plot predicted values:","code":"fit <- lm(re78 ~ treat + age + educ + married + race +             nodegree + re74 + re75, data = lalonde) s <- clarify::sim(fit) est <- sim_setx(s, x = list(treat = 0), x1 = list(treat = 1),                 verbose = FALSE) summary(est) #>           Estimate   2.5 %  97.5 % #> treat = 0   6686.0  5355.6  7909.3 #> treat = 1   8234.3  6405.9 10060.0 #> FD          1548.2    12.5  3096.9  plot(est)"},{"path":"/articles/Zelig.html","id":"rare-events-logit","dir":"Articles","previous_headings":"","what":"Rare-events logit","title":"Translating Zelig to clarify","text":"Zelig uses special method logistic regression rare events described King Zeng (2001). primary implementation method R. However, newer methods developed perform similarly better method King Zeng (Puhr et al. 2017) implemented R packages compatible clarify, logistf brglm2. , ’ll use lalonde dataset constructed rare outcome variable demonstrate perform rare events logistic regression Zelig clarify.","code":"data(\"lalonde\", package = \"MatchIt\")  #Rare outcome: 1978 earnings over $20k; ~6% prevalence lalonde$re78_20k <- lalonde$re78 >= 20000"},{"path":"/articles/Zelig.html","id":"zelig-workflow-1","dir":"Articles","previous_headings":"Rare-events logit","what":"Zelig workflow","title":"Translating Zelig to clarify","text":"Zelig, fit rare events logistic model using zelig() model = \"relogit\". can compute predicted values representative values using setx() Zelig::sim() .","code":"fit <- zelig(re78_20k ~ treat + age + educ + married + race +                nodegree + re74 + re75, data = lalonde,              model = \"relogit\", cite = FALSE)  fit fit <- setx(fit, treat = 0) fit <- setx1(fit, treat = 1)  fit <- Zelig::sim(fit)  fit plot(fit)"},{"path":"/articles/Zelig.html","id":"clarify-workflow-1","dir":"Articles","previous_headings":"Rare-events logit","what":"clarify workflow","title":"Translating Zelig to clarify","text":", ’ll use logistf::logistif() flic = TRUE, performs variation Firth’s logistic regression correction bias intercept (Puhr et al. 2017). can compute predictions representative values using clarify::sim() sim_setx().","code":"fit <- logistf::logistf(re78_20k ~ treat + age + educ + married + race +                           nodegree + re74 + re75, data = lalonde,                         flic = TRUE)  summary(fit) #> logistf::logistf(formula = re78_20k ~ treat + age + educ + married +  #>     race + nodegree + re74 + re75, data = lalonde, flic = TRUE) #>  #> Model fitted by Penalized ML #> Coefficients: #>                      coef     se(coef)    lower 0.95    upper 0.95      Chisq #> (Intercept) -9.313465e+00 2.036981e+00 -1.330595e+01 -5.3209820512 24.4427501 #> treat        1.106769e+00 6.165332e-01 -1.029333e-01  2.3139987641  3.2185792 #> age          4.144350e-02 2.147498e-02 -8.432745e-04  0.0825427498  3.6937075 #> educ         2.936673e-01 1.283624e-01  4.612509e-02  0.5477908006  5.4633187 #> married      2.909164e-01 4.769332e-01 -6.309243e-01  1.2240602694  0.3844676 #> racehispan   1.056388e+00 7.276772e-01 -4.150796e-01  2.4305568008  2.0440063 #> racewhite    5.431919e-01 6.160352e-01 -6.255328e-01  1.7838676828  0.8008622 #> nodegree     2.868319e-01 5.852738e-01 -8.531608e-01  1.4243907533  0.2462839 #> re74         1.108995e-04 2.821452e-05  5.775266e-05  0.0001664918 17.0427331 #> re75         4.457916e-05 4.720736e-05 -4.706292e-05  0.0001334568  0.9472092 #>                        p method #> (Intercept) 7.655103e-07      1 #> treat       7.280680e-02      2 #> age         5.461808e-02      2 #> educ        1.941973e-02      2 #> married     5.352219e-01      2 #> racehispan  1.528067e-01      2 #> racewhite   3.708357e-01      2 #> nodegree    6.197040e-01      2 #> re74        3.654797e-05      2 #> re75        3.304307e-01      2 #>  #> Method: 1-Wald, 2-Profile penalized log-likelihood, 3-None #>  #> Likelihood ratio test=65.80085 on 9 df, p=1.007627e-10, n=614 #> Wald test = 179.4243 on 9 df, p = 0 s <- clarify::sim(fit)  est <- sim_setx(s, x = list(treat = 0), x1 = list(treat = 1),                 verbose = FALSE)  summary(est) #>           Estimate    2.5 %   97.5 % #> treat = 0  0.02341  0.00817  0.06940 #> treat = 1  0.06760  0.01760  0.21703 #> FD         0.04419 -0.00148  0.18017 plot(est)"},{"path":"/articles/Zelig.html","id":"estimating-the-att-after-matching","dir":"Articles","previous_headings":"","what":"Estimating the ATT after matching","title":"Translating Zelig to clarify","text":"’ll use lalonde dataset perform propensity score matching fit linear model re78 function treatment treat, covariates, interaction. model, ’ll compute ATT treat using Zelig clarify.","code":"data(\"lalonde\", package = \"MatchIt\")  m.out <- MatchIt::matchit(treat ~ age + educ + married + race +                             nodegree + re74 + re75, data = lalonde,                           method = \"nearest\")"},{"path":"/articles/Zelig.html","id":"zelig-workflow-2","dir":"Articles","previous_headings":"Estimating the ATT after matching","what":"Zelig workflow","title":"Translating Zelig to clarify","text":"Zelig, fit model using zelig() directly matchit object: Next, use ATT() request ATT treat simulate values:","code":"fit <- zelig(re78 ~ treat * (age + educ + married + race +                                nodegree + re74 + re75),              data = m.out, model = \"ls\", cite = FALSE) fit <- ATT(fit, \"treat\") fit plot(fit)"},{"path":"/articles/Zelig.html","id":"clarify-workflow-2","dir":"Articles","previous_headings":"Estimating the ATT after matching","what":"clarify workflow","title":"Translating Zelig to clarify","text":"clarify, need extract matched dataset fit model outside clarify using another package. Next, simulate model coefficients using clarify::sim(). performed pair matching, request cluster-robust standard error: Next, use sim_ame() request average marginal effect treat within subset treated units: Finally, can summarize plot ATT:","code":"m.data <- MatchIt::match.data(m.out)  fit <- lm(re78 ~ treat * (age + educ + married + race +                             nodegree + re74 + re75),           data = m.data) s <- clarify::sim(fit, vcov = ~subclass) est <- sim_ame(s, var = \"treat\", subset = treat == 1,                contrast = \"diff\", verbose = FALSE) summary(est) #>         Estimate 2.5 % 97.5 % #> E[Y(0)]     5228  4129   6393 #> E[Y(1)]     6349  5179   7564 #> Diff        1121  -295   2566  plot(est)"},{"path":"/articles/Zelig.html","id":"combining-results-after-multiple-imputation","dir":"Articles","previous_headings":"","what":"Combining results after multiple imputation","title":"Translating Zelig to clarify","text":"’ll use africa dataset Amelia demonstrate combining estimates multiple imputation. analysis also demonstrated using clarify end vignette(\"clarify\"). First multiply impute data using amelia() using specification Amelia documentation.","code":"library(Amelia) data(\"africa\", package = \"Amelia\") # Multiple imputation a.out <- amelia(x = africa, m = 10, cs = \"country\",                 ts = \"year\", logs = \"gdp_pc\", p2s = 0)"},{"path":"/articles/Zelig.html","id":"zelig-workflow-3","dir":"Articles","previous_headings":"Combining results after multiple imputation","what":"Zelig workflow","title":"Translating Zelig to clarify","text":"Zelig, can supply amelia object directly data argument zelig() fit model imputed dataset: Summarizing coefficient estimates simulation can done using summary(): can use Zelig::sim() setx() compute predictions specified values predictors: Zelig allow combine predicted values across imputations.","code":"fit <- zelig(gdp_pc ~ infl * trade, data = a.out,              model = \"ls\", cite = FALSE) summary(fit) fit <- setx(fit, infl = 0, trade = 40) fit <- setx1(fit, infl = 0, trade = 60)  fit <- Zelig::sim(fit) fit plot(fit)"},{"path":"/articles/Zelig.html","id":"clarify-workflow-3","dir":"Articles","previous_headings":"Combining results after multiple imputation","what":"clarify workflow","title":"Translating Zelig to clarify","text":"clarify combine coefficients, unlike zelig(); instead, models fit using Amelia::(). view combined coefficient estimates, use Amelia::mi.combine(). Derived quantities can computed using clarify::misim() sim_apply() wrappers () output, list regression model fits:","code":"#Use Amelia functions to model and combine coefficients fits <- with(a.out, lm(gdp_pc ~ infl * trade))  mi.combine(fits) #> # A tibble: 4 × 8 #>   term        estimate std.error statistic  p.value     df      r miss.info #>   <chr>          <dbl>     <dbl>     <dbl>    <dbl>  <dbl>  <dbl>     <dbl> #> 1 (Intercept) -171.      118.        -1.44 1.85e+ 0 12575. 0.0275    0.0269 #> 2 infl          12.2       9.42       1.29 1.97e- 1 72291. 0.0113    0.0112 #> 3 trade         21.2       1.83      11.6  4.85e-31 19660. 0.0219    0.0215 #> 4 infl:trade    -0.289     0.141     -2.05 1.96e+ 0 83194. 0.0105    0.0104 #Simulate coefficients, 100 in each of 10 imputations s <- misim(fits, n = 100)  #Compute predictions at specified values est <- sim_setx(s, x = list(infl = 0, trade = 40),                 x1 = list(infl = 0, trade = 60),                 verbose = FALSE)  summary(est) #>            Estimate 2.5 % 97.5 % #> trade = 40      678   552    831 #> trade = 60     1103   961   1298 #> FD              424   336    523  plot(est)"},{"path":[]},{"path":"/articles/clarify.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"`clarify`: Simulation-Based Inference for Regression Models","text":"Although regression models frequently used empirical research study relationships among variables, often quantity substantive interest one coefficients model, rather quantity derived coefficients, predicted values average marginal effects. Quantifying uncertainty derived quantities (.e., computing standard errors, confidence intervals, p-values) requires additional processing. Several methods exist, including delta method, bootstrap, simulation-based inference. clarify implements simulation-based inference, describe along methods. delta method involves computing first-order Taylor series approximation variance derived quantity, standard Wald-based inference relies computing quantiles based Normal distribution using compute p-values confidence intervals. clarify implements alternative delta method—simulation-based inference—involves simulating “posterior” distribution derived quantities. Simulation-based inference require understanding Taylor series calculus underlies , can make palatable nontechnical audiences easier learn students without necessarily sacrificing statistical performance (King, Tomz, Wittenberg 2000; Zelner 2009). studies found simulation-based inference performs well better delta method computing derived quantities (.e., respect achieving close nominal coverage confidence intervals), especially complicated derived quantities smaller samples (MacKinnon, Lockwood, Williams 2004; Hole 2007; Herron 1999). empirical performance particularly well studied context mediation analysis, quantities interest products ratios regression coefficients, shown perform well relative delta method due non-Normality quantities (Tofighi MacKinnon 2016; Preacher Selig 2012). methodology clarify relies developed Krinsky Robb (1986) described King, Tomz, Wittenberg (2000) Herron (1999). Simulation-based inference involves taking draws specified joint distribution model parameters, computing derived quantities draws, collecting derived quantities “posterior” distribution, uncertainty measures (standard errors confidence intervals) can computed. method assumes model parameters drawn multivariate Normal (T) distribution means estimated values covariance equal asymptotic covariance matrix estimated values, standard assumption motivated central limit theorem underlies usual inference original model parameters. Arriving posterior distribution require taking derivatives making approximations beyond usually used inference model parameter estimates, except approximation due Monte Carlo error induced sampling finite number simulations (can always reduced increasing number draws cost increased computing time). nonparametric bootstrap another alternative delta method inference require analytic approximations (Efron Tibshirani 1986); bootstrapping typically involves re-sampling individuals sample, fitting model bootstrap sample, computing quantity interest model. Although bootstrapping tends work well practice, especially complex non-Normal estimators, refitting model repeatedly can prohibitively time-consuming computationally expensive, especially complicated models large datasets. Simulation-based inference requires model fit , simulations involve taking draws distribution produced single set estimated parameters, making much quicker practice allowing user capitalize already valid estimation model parameters. Methods computing valid confidence intervals cases quantity interest complicated distribution better developed bootstrapping, however (Efron Tibshirani 1986). formally, fit regression model yi=f(xi;β)y_i = f(x_i; \\beta), linear generalized linear model model coefficients β\\beta. assume β̂∼MVN(β,Σβ̂)\\hat{\\beta} \\sim \\text{MVN}(\\beta, \\Sigma_{\\hat{\\beta}}) β̂\\hat{\\beta} vector estimates β\\beta Σβ̂\\Sigma_{\\hat{\\beta}} asymptotic covariance matrix. define function τ(β)\\tau(\\beta) represents quantity interest derived model parameters, compute estimate τ(β)̂\\widehat{\\tau(\\beta)} τ(β̂)\\tau(\\hat{\\beta}). perform simulation-based inference, take MM draws β̃(j)\\tilde{\\beta}^{(j)} j∈(1,…,M)j\\(1, \\dots, M) multivariate Normal distribution mean vector μ=β̂\\mu = \\hat{\\beta} covariance Σ=Σ̂β̂\\Sigma = \\hat{\\Sigma}_{\\hat{\\beta}}, Σ̂β̂\\hat{\\Sigma}_{\\hat{\\beta}} estimate asymptotic covariance matrix parameter estimates. use distribution τ̃=τ(β̃)\\tilde{\\tau}=\\tau(\\tilde{\\beta}) “posterior” distribution τ(β)̂\\widehat{\\tau(\\beta)}, compute variance σ̂τ(β)̂2=1M−1∑j=1M(τ̃(j)−τ̃‾)2\\begin{equation} \\hat\\sigma^2_{\\widehat{\\tau(\\beta)}} = \\frac{1}{M-1}\\sum^M_{j=1}{(\\tilde{\\tau}^{(j)} - \\bar{\\tilde{\\tau}})^2} \\end{equation} quantile 100(1−α)%100(1-\\alpha)\\% confidence interval limits [τ̃(α2),τ̃(1−α2)]\\left[\\tilde{\\tau}_{(\\frac{\\alpha}{2})}, \\tilde{\\tau}_{(1-\\frac{\\alpha}{2})}\\right] τ̃(q)\\tilde{\\tau}_{(q)} qqth value τ̃\\tilde{\\tau} arranged ascending order (.e., qqth quantile empirical cumulative distribution function τ̃\\tilde{\\tau}). Simulation-based Wald-type confidence intervals can computed [τ(β̂)+σ̂τ(β)̂Zα2,τ(β̂)+σ̂τ(β)̂Z1−α2]\\begin{equation} \\left[\\tau(\\hat{\\beta}) + \\hat\\sigma_{\\widehat{\\tau(\\beta)}} Z_{\\frac{\\alpha}{2}}, \\tau(\\hat{\\beta}) + \\hat\\sigma_{\\widehat{\\tau(\\beta)}} Z_{1-\\frac{\\alpha}{2}} \\right] \\end{equation} ZqZ_q qqth quantile standard Normal distribution. delta method-based Wald-type confidence intervals use formula first-order Taylor approximation asymptotic variance: σ̂τ(β)̂2=∇τ(β̂)Σβ̂∇τ′(β̂)\\begin{equation} \\hat\\sigma^2_{\\widehat{\\tau(\\beta)}}=\\nabla\\tau(\\hat{\\beta}) \\Sigma_{\\hat{\\beta}} \\nabla\\tau'(\\hat{\\beta}) \\end{equation} ∇τ(β̂)\\nabla\\tau(\\hat{\\beta}) gradient τ(β)\\tau(\\beta) respect β\\beta evaluated β̂\\hat{\\beta}. compute p-value hypothesis test involving quantity interest, .e., H0:τ(β)=τ0\\text{H}_0: \\tau (\\beta) = \\tau_0 given null value τ0\\tau_0, can invert confidence interval (Thulin 2024); , find largest value α\\alpha τ0\\tau_0 within confidence interval use α\\alpha p-value test. Wald-based inference (either using simulation-based variance delta method-based variance), equivalent performing standard two-sided Z-test using test statistic Z=τ(β̂)−τ0σ̂τ(β)̂\\begin{equation} Z=\\frac{\\tau(\\hat\\beta)-\\tau_0}{\\hat\\sigma_{\\widehat{\\tau(\\beta)}}} \\end{equation} One benefit using quantile p-values inference equivalent tests hypothesis always yield identical p-values; example, testing equality two derived quantities yield p-value comparing difference quantities null hypothesis 0 ratio quantities null hypothesis 1, hypothesis true true. One expect simulation-based quantile inference, simulation-based Wald inference, delta method-based Wald inference align posterior Normally distributed around estimate, case discrepancies due Monte Carlo error simulated values (therefore shrink increasing draws). However, low values α\\alpha, may require many draws simulation-based intervals stabilize; delta method-based intervals subject error. cases results might diverge: cases, first-order Taylor series approximation variance may poor, though practice approximation error small shrinks quickly increasing sample size. posterior distribution non-Normal symmetric around estimate, quantile intervals may accurate (.e., sense achieving closer nominal coverage) rely quantiles Normal distribution (Tofighi MacKinnon 2016). Another potential advantage quantile intervals can Wald-intervals monotonic transformation estimate symmetric distribution centered around transformed estimate, quantile intervals can achieve correct coverage without requiring knowledge transformation required (Efron Tibshirani 1986); true quantile-based p-values well. distribution centered around estimate monotonic transformation make , though, neither quantile-based Wald-based intervals expected perform well, quantile intervals yield even worse coverage Wald-based intervals, phenomenon occurs context bootstrapping (Efron Tibshirani 1986)1. informal falsification test whether monotonic transformation exists whether median simulated estimates aligned point estimate; , monotonic transformation yield symmetric quantile interval desired coverage.","code":""},{"path":"/articles/clarify.html","id":"related-software","dir":"Articles","previous_headings":"","what":"Related software","title":"`clarify`: Simulation-Based Inference for Regression Models","text":"Similar functionality exists CLARIFY package Stata2 (Tomz, Wittenberg, King 2003) used available Zelig R package (Imai, King, Lau 2008), though differences implementations. clarify provides additional flexibility allowing user request derived quantity, addition providing shortcuts common quantities, including predictions representative values, average marginal effects, average dose-response functions (described ). clarify relies can seen companion marginaleffects package (Arel-Bundock, Greifer, Heiss 2024), offers similar functionality primarily uses delta method calculating uncertainty (though simulation-based inference supported limited capacity well).","code":""},{"path":"/articles/clarify.html","id":"using-clarify","dir":"Articles","previous_headings":"","what":"Using clarify","title":"`clarify`: Simulation-Based Inference for Regression Models","text":"four steps using clarify: Fit model data using modeling functions supported packages. Use sim() take draws multivariate distribution estimated model coefficients. Use sim_apply() wrappers sim_setx(), sim_ame(), sim_adrf() compute derived quantities using simulated set coefficients. Use summary() plot() summarize visualize distribution derived quantities perform inference . sections , describe implement steps detail. First, load clarify using library(). running example, use lalonde dataset MatchIt package (Ho et al. 2011), contains data 614 participants enrolled job training program sampled survey (Dehejia Wahba 1999). treatment variable treat outcome re78, variables confounders. Although original use dataset estimate effect treat re78, use generally demonstrate clarify’s capabilities. addition, use transformation outcome variable demonstrate applications nonlinear models, benefits simulation-based inference apparent.","code":"library(clarify) data(\"lalonde\", package = \"MatchIt\")  # Create a binary outcome variable lalonde$re78_0 <- ifelse(lalonde$re78 > 0, 1, 0)  head(lalonde) #>      treat age educ   race married nodegree re74 re75       re78 re78_0 #> NSW1     1  37   11  black       1        1    0    0  9930.0460      1 #> NSW2     1  22    9 hispan       0        1    0    0  3595.8940      1 #> NSW3     1  30   12  black       0        0    0    0 24909.4500      1 #> NSW4     1  27   11  black       0        1    0    0  7506.1460      1 #> NSW5     1  33    8  black       0        1    0    0   289.7899      1 #> NSW6     1  22    9  black       0        1    0    0  4056.4940      1"},{"path":"/articles/clarify.html","id":"fitting-the-model","dir":"Articles","previous_headings":"Using clarify","what":"1. Fitting the model","title":"`clarify`: Simulation-Based Inference for Regression Models","text":"first step fit model. clarify can operate large set models (supported marginaleffects), including generalized linear models, multinomial models, multivariate models, instrumental variable models, many available R packages. Even clarify offer direct support given model, ways use functionality regardless (explained detail ). computing derived quantities, critical parameterize model way coefficients interpretable, e.g., using model interpretable coefficients centering predictors. , fit probit regression model outcome given treatment confounders. Coefficients probit regression straightforward interpretation, matter; quantities interest can expressed derived quantities—functions model parameters, predictions, counterfactual predictions, averages contrasts .","code":"fit <- glm(re78_0 ~ treat * married + age + educ + race +              nodegree + re74 + re75, data = lalonde,            family = binomial(\"probit\"))"},{"path":"/articles/clarify.html","id":"drawing-from-the-coefficient-distribution","dir":"Articles","previous_headings":"Using clarify","what":"2. Drawing from the coefficient distribution","title":"`clarify`: Simulation-Based Inference for Regression Models","text":"fitting model, use sim() draw coefficients sampling distribution. sampling distribution assumed multivariate Normal multivariate T appropriate degrees freedom, mean vector equal estimated coefficients covariance matrix equal asymptotic covariance matrix extracted model. arguments sim() listed : fit – fitted model object, output call fitting function (e.g., glm()) n – number simulated values draw; default, 1000. values yield replicable precise results cost speed. vcov – either covariance matrix estimated coefficients, function used extract model (e.g., sandwich::vcovHC() robust covariance matrix), string formula giving code extracting covariance matrix, passed marginaleffects::get_vcov(). left unspecified, default covariance matrix extracted model. coefs – either vector coefficients sampled function extract fitted model. left unspecified, default coefficients extracted model. Typically need specified. dist – name distribution draw sampled coefficients. Can \"normal\" Normal distribution t(#) T-distribution, # represents degrees freedom. left unspecified, sim() decide distribution makes sense given characteristics model (decision made insight::get_df() type = \"wald\"). Typically need specified. one’s model supported clarify, one can omit fit argument just specify vcov coefs argument, draw coefficients distribution named dist (\"normal\" default). sim() uses random number generator draw sampled coefficients sampling distribution, seed set using set.seed() ensure results replicable across sessions. Using iterations (.e., increasing n) yields results stable across runs even seed set. output call sim() clarify_sim object, contains sampled coefficients, original model fit object supplied, coefficients covariance matrix used sample.","code":"sim(fit = , n = , vcov = , coefs = , dist = ) set.seed(1234)  # Drawing 1000 simulated coefficients using an HC2 robust # covariance matrix s <- sim(fit, n = 1000,          vcov = \"HC2\")  s #> A `clarify_sim` object #>  - 11 coefficients, 1000 simulated values #>  - sampled distribution: multivariate normal #>  - original fitting function call: #>  #> glm(formula = re78_0 ~ treat * married + age + educ + race +  #>     nodegree + re74 + re75, family = binomial(\"probit\"), data = lalonde)"},{"path":"/articles/clarify.html","id":"computing-derived-quantities","dir":"Articles","previous_headings":"Using clarify","what":"3. Computing derived quantities","title":"`clarify`: Simulation-Based Inference for Regression Models","text":"sampling coefficients, one can compute derived quantities set sampled coefficients store result, represents “posterior” distribution derived quantity, well original coefficients, used final estimates. core functionality provided sim_apply(), accepts clarify_sim object sim() function compute return one derived quantities, applies function set simulated coefficients. arguments sim_apply() : sim – clarify_sim object; output call sim(). FUN – function takes either model fit object vector coefficients returns one derived quantities. first argument named fit take model fit object coefs take coefficients. verbose – whether display progress bar. cl – argument controls parallel processing, can number cores use cluster object resulting parallel::makeCluster(). ... – arguments FUN. FUN argument can specified one two ways: either function takes model fit object (e.g., glm lm object, output call glm() lm()) function takes vector coefficients. latter always work former works supported models. function takes model fit object, sim_apply() first insert set sampled coefficients model fit object supply modified model FUN. example, let derived quantity interest predicted probability outcome participant PSID1. specify FUN function follows: fit object supplied function one coefficients set values draw sampling distribution generated sim(). supply function sim_apply() simulate sampling distribution predicted value interest: resulting clarify_est object contains simulated estimates matrix form well estimate computed original coefficients. examine posterior distribution shortly, first demonstrate computing derived quantity coefficients directly. race variable factor, black category used reference level, immediately clear whether difference coefficients racehispan racewhite, represent non-reference categories hispan white. compare two directly, can use sim_apply() compute derived quantity corresponds difference . function supplied FUN can arbitrarily complicated return many derived quantities one wants, though slower run FUN , longer take simulate derived quantities. Using parallel processing supplying argument cl can sometimes dramatically speed evaluation. several functions clarify serve convenience wrappers sim_apply() automate common derived quantities interest. include sim_setx() – computing predicted values first differences representative user-specified values predictors sim_ame() – computing average adjusted predictions, contrasts average adjusted predictions, average marginal effects sim_adrf() – computing average dose-response functions average marginal effects functions described sections . addition, functions methods clarify_est objects, including cbind() combining two clarify_est objects together transform() computing quantities derived already-computed derived quantities. also described sections .","code":"sim_apply(sim = , FUN = , verbose = , cl = , ...) sim_fun1 <- function(fit) {   predict(fit, newdata = lalonde[\"PSID1\",], type = \"response\") } est1 <- sim_apply(s, FUN = sim_fun1, verbose = FALSE)  est1 #> A `clarify_est` object (from `sim_apply()`) #>  - 1000 simulated values #>  - 1 quantity estimated:              #>  PSID1 0.9757 sim_fun2 <- function(coefs) {   hispan <- unname(coefs[\"racehispan\"])   white <- unname(coefs[\"racewhite\"])      c(\"w - h\" = white - hispan) }  est2 <- sim_apply(s, FUN = sim_fun2, verbose = FALSE)  est2 #> A `clarify_est` object (from `sim_apply()`) #>  - 1000 simulated values #>  - 1 quantity estimated:                #>  w - h -0.09956"},{"path":"/articles/clarify.html","id":"summarize-and-visualize-the-simulated-distribution","dir":"Articles","previous_headings":"Using clarify","what":"4. Summarize and visualize the simulated distribution","title":"`clarify`: Simulation-Based Inference for Regression Models","text":"examine uncertainty around perform inference estimated quantities, can use plot() summary() clarify_est object. plot() displays density plot resulting estimates across simulations, markers identifying point estimate (computed using original model coefficients recommended Rainey (2023)) , optionally, uncertainty bounds (function like confidence credible interval bounds). arguments plot() : x – clarify_est object (output call sim_apply()). parm – names indices quantities plotted one estimated sim_apply(); unspecified, plotted. ci – whether display lines uncertainty bounds. default TRUE display . level – ci TRUE, desired two-sided confidence level. default .95 bounds .025 .975 quantiles method (see ) \"quantile\". method – ci TRUE, method used compute bounds. Allowable methods include Normal approximation (\"wald\") using quantiles resulting distribution (\"quantile\"). Normal approximation involves multiplying standard deviation estimates (.e., functions like standard error sampling distribution) critical Z-statistic computed using (1-level)/2 create symmetric margin error around point estimate. default \"quantile\" instead use quantile-based bounds. reference – whether display normal density plot estimate indicator line median estimate. default FALSE omit . , plot first estimate computed , predicted probability participant PSID1:  Overlaid plot red Normal distribution mean standard deviation simulated values; requested setting reference = TRUE. plot, one can see distribution simulated values non-Normal, asymmetrical, centered around estimate, values falling 1 outcome predicted probability. Given non-Normality, quantile-based bounds may appropriate resulting Normal approximation, bounds computed Normal approximation outside bounds estimate. blue reference line median estimates close point estimate, suggesting possible monotonic transformation symmetric distribution around estimate3. plot ggplot object can modified using ggplot2 syntax. can use summary() display value point estimate, uncertainty bounds, statistics describe distribution estimates. arguments summary() : object – clarify_est object (output call sim_apply()). parm – names indices quantities displayed one estimated sim_apply(); unspecified, displayed. level – desired two-sided confidence level. default .95 bounds .025 .975 quantiles method (see ) \"quantile\". method – method used compute uncertainty bounds. Allowable methods include Normal approximation (\"wald\") using quantiles resulting distribution (\"quantile\"). See plot() . null – optional argument specifying desired null value hypothesis test estimates. specified, p-value computed using either standard Z-test (method \"wald\") inversion uncertainty interval (described ). default display p-values. can use summary() default arguments first clarify_est object view point estimate quantile-based uncertainty bounds. second estimated quantity, difference two regression coefficients, closer Normally distributed, plot demonstrates (expected theoretically), use Normal approximation test hypothesis difference differs 0.  uncertainty intervals p-values summary() output computed using Normal approximation set method = \"wald\", p-value test estimate equal 0 returned set null = 0. Note Normal approximation used simulated posterior distribution close Normal centered around estimate (.e., mean simulated values [red vertical line] coincides estimate computed original coefficients [black vertical line]). cases, however, delta method likely perform well, better, benefits apply (.e., computationally quicker subject Monte Carlo error).","code":"plot(x = , parm = , ci = , level = , method = , reference =) plot(est1, reference = TRUE, ci = FALSE) summary(object = , parm = , level = , method = , null = ) summary(est1) #>       Estimate 2.5 % 97.5 % #> PSID1    0.976 0.900  0.997 plot(est2, reference = TRUE, ci = FALSE) summary(est2, method = \"wald\", null = 0) #>       Estimate   2.5 %  97.5 % Std. Error Z value P-value #> w - h  -0.0996 -0.5150  0.3159     0.2120   -0.47    0.64"},{"path":"/articles/clarify.html","id":"wrappers-for-sim_apply-sim_setx-sim_ame-and-sim_adrf","dir":"Articles","previous_headings":"","what":"Wrappers for sim_apply(): sim_setx(), sim_ame(), and sim_adrf()","title":"`clarify`: Simulation-Based Inference for Regression Models","text":"sim_apply() can used compute simulated posterior distribution arbitrary derived quantity interest, quantities common applied research may otherwise somewhat challenging program hand, clarify provides shortcut functions make computing quantities simple. functions include sim_setx(), sim_ame(), sim_adrf(). can used regression models compatible clarify supplied original call sim(). Like sim_apply(), functions named sim_*(), signifies used object produced sim() (.e., clarify_sim object). (Multiple calls functions can applied clarify_sim object combined; see cbind() section .) functions described .","code":""},{"path":"/articles/clarify.html","id":"sim_setx-predictions-at-representative-values","dir":"Articles","previous_headings":"Wrappers for sim_apply(): sim_setx(), sim_ame(), and sim_adrf()","what":"sim_setx(): predictions at representative values","title":"`clarify`: Simulation-Based Inference for Regression Models","text":"sim_setx() provides interface compute predictions representative user-supplied values predictors. example, might want know effect treatment “typical” individual, corresponds contrast two model-based predictions (.e., one treatment one control unit “typical” covariate values). functionality mirrors setx() setx1() functionality Zelig (name originates) provides similar functionality functions modelbased, emmeans, effects, ggeffects. predictor, user can specify whether want predictions specific values “typical” values, defined clarify mode unordered categorical binary variables, median ordered categorical variables, mean continuous variables. Predictions multiple predictor combinations can requested specifying values used create grid predictor values, grid can supplied data frame desired predictor profiles. addition, “first difference”, defined difference predictions two predictor combinations, can computed. arguments sim_setx() follows: sim – clarify_sim object; output call sim(). x – named list containing requested values predictors, e.g., list(v1 = 1:4, v2 = \"\"), data frame containing desired profiles. predictors included set “typical” value defined . x1 – optional named list data frame similar x except value one predictor changed. specified, first difference computed covariate combination defined x (one combination allowed x1 specified) covariate combination defined x1. outcome – string containing name outcome interest multivariate (multiple outcome) model supplied sim() outcome category interest multinomial model supplied sim(). univariate (single outcome) binary outcomes, ignored. type – string containing type predicted value return. cases, can left unspecified request predictions scale outcome. verbose – whether display progress bar. cl – argument controls parallel processing, can number cores use cluster object resulting parallel::makeCluster(). , use sim_setx() examine predicted values outcome control treated units, re75 set 0 20000, race set “black”. use summary() resulting output, can see estimates uncertainty intervals (calculated using quantiles default). see complete grid predictor values used predictions, helps identify “typical” values predictors, can access \"setx\" attribute object: can plot distributions simulated values using plot(), also separates predictions predictor values (often clearer without uncertainty bounds). var argument controls variable used faceting plots.  One can see delta method Normal approximation may yielded uncertainty intervals outside plausible range estimate without applying knowledge correct transformation use avoid . continuous variable many levels included grid predictors, something like dose-response function typical unit can generated. , set re75 vary 0 20000 steps 2000. plot output, can see predictions varies across levels re75:  return display average dose-response functions using sim_adrf() later. Finally, can use sim_setx() compute first differences, contrast two covariate combinations. supply one covariate profile x another x1, sim_setx() simulates two predicted values difference. , simulate first difference treated control unit re75 0 typical values covariates: use summary(), see estimates predicted values first difference (“FD”): possible compute first differences without using x1 using transform(), describe later.","code":"sim_setx(sim = , x = , x1 = , outcome = , type = , verbose = , cl = ) est3 <- sim_setx(s,                  x = list(treat = 0:1,                           re75 = c(0, 20000),                           race = \"black\"),                  verbose = FALSE) summary(est3) #>                         Estimate 2.5 % 97.5 % #> treat = 0, re75 = 0        0.667 0.548  0.772 #> treat = 1, re75 = 0        0.712 0.607  0.799 #> treat = 0, re75 = 20000    0.938 0.726  0.995 #> treat = 1, re75 = 20000    0.953 0.769  0.996 attr(est3, \"setx\") #>                         treat married      age     educ  race nodegree     re74 #> treat = 0, re75 = 0         0       0 27.36319 10.26873 black        1 4557.547 #> treat = 1, re75 = 0         1       0 27.36319 10.26873 black        1 4557.547 #> treat = 0, re75 = 20000     0       0 27.36319 10.26873 black        1 4557.547 #> treat = 1, re75 = 20000     1       0 27.36319 10.26873 black        1 4557.547 #>                          re75 #> treat = 0, re75 = 0         0 #> treat = 1, re75 = 0         0 #> treat = 0, re75 = 20000 20000 #> treat = 1, re75 = 20000 20000 plot(est3, var = \"re75\", ci = FALSE) est4 <- sim_setx(s,                  x = list(treat = 0:1,                           re75 = seq(0, 20000, by = 2000),                           race = \"black\"),                  verbose = FALSE) plot(est4) est5 <- sim_setx(s,                  x = list(treat = 0, re75 = 0),                  x1 = list(treat = 1, re75 = 0),                  verbose = FALSE) summary(est5) #>           Estimate   2.5 %  97.5 % #> treat = 0   0.7856  0.6846  0.8551 #> treat = 1   0.8213  0.7123  0.9037 #> FD          0.0357 -0.0517  0.1192"},{"path":"/articles/clarify.html","id":"sim_ame-average-adjusted-predictions-and-average-marginal-effects","dir":"Articles","previous_headings":"Wrappers for sim_apply(): sim_setx(), sim_ame(), and sim_adrf()","what":"sim_ame(): average adjusted predictions and average marginal effects","title":"`clarify`: Simulation-Based Inference for Regression Models","text":"Using predicted values effects representative values one way summarize regression models, another way compute average adjusted predictions (AAPs), contrasts AAPs, average marginal effects (AMEs). definitions terms may vary names concepts differ across sources, define AAPs average predicted values units setting one predictor chosen value, define AMEs binary predictors contrast two AAPs continuous predictors average instantaneous rate change AAP corresponding small change predictor observed values across units4 (Long Freese 2014). arguments sim_ame() follows: sim – clarify_sim object; output call sim(). var – name focal variable compute AAPs AMEs, list containing values AAPs computed. subset – logical vector, evaluated original dataset used fit model, defining subset units AAPs AMEs computed. – name one variables AAPs computed within subgroups. Can supplied character vector variable names one-sided formula. contrast – name effect measure used contrast AAPs. continuous outcomes, \"diff\" requests difference means, others available binary outcomes, including \"rr\" risk ratio, \"\" odds ratio, \"nnt\" number needed treat, among others. specified, AAPs computed variable named var categorical specific values focal variable specified var. Ignored variable named var continuous specific values specified AME quantity computed. var names multi-category categorical variable, contrast used; see section describing transform() computing contrasts . outcome – string containing name outcome interest multivariate (multiple outcome) model supplied sim() outcome category interest multinomial model supplied sim(). univariate (single outcome) binary outcomes, ignored. type – string containing type predicted value return. cases, can left unspecified request predictions scale outcome (e.g., probabilities binary outcomes). eps – value observed values variable named var changed continuous compute AME. usually need specified. verbose – whether display progress bar. cl – argument controls parallel processing, can number cores use cluster object resulting parallel::makeCluster(). , use sim_ame() compute AME treat just among treated (causal inference, known average treatment effect treated, ATT (Greifer Stuart 2023)). request estimate risk ratio scale. can use summary() display estimates uncertainty intervals. , also use null include test null hypothesis risk ratio equal 1. see estimates AAPs, E[Y(0)] expected value outcome setting treat 0 E[Y(1)] expected value outcome setting treat 1, risk ratio RR. p-value test risk ratio aligns uncertainty interval containing 1. instead wanted risk difference odds ratio, re-compute AAPs. Instead, can use transform() compute new derived quantity computed AAPs. section transform() demonstrates . can compute AME continuous predictor. , consider age (just demonstration; analysis valid interpretation). can use summary() display AME estimate uncertainty interval. AME named E[dY/d(age)], signifies derivative computed (precisely, average unit-specific derivatives). estimate can interpreted like slope linear regression model, single summary effect predictor often coarse capture nonlinear relationships. section explains compute average dose-response functions continuous predictors, provide complete picture effects outcome. , examine effect modification ATT predictor married using argument estimate AAPs ratio within levels married: presence effect modification can tested testing contrast effects computed within level variable; demonstrated section transform() .","code":"sim_ame(sim = , var = , subset = , by = , contrast = , outcome = ,         type = , eps = , verbose = , cl = ) est6 <- sim_ame(s,                 var = \"treat\",                 subset = treat == 1,                 contrast = \"rr\",                 verbose = FALSE) summary(est6, null = c(`RR` = 1)) #>         Estimate 2.5 % 97.5 % P-value #> E[Y(0)]    0.687 0.603  0.757       . #> E[Y(1)]    0.755 0.689  0.814       . #> RR         1.100 0.966  1.276    0.15 est7 <- sim_ame(s,                 var = \"age\",                 verbose = FALSE) summary(est7) #>              Estimate    2.5 %   97.5 % #> E[dY/d(age)] -0.00605 -0.00933 -0.00222 est6b <- sim_ame(s,                  var = \"treat\",                  subset = treat == 1,                  by = ~married,                  contrast = \"rr\",                  verbose = FALSE)  summary(est6b) #>           Estimate 2.5 % 97.5 % #> E[Y(0)|0]    0.691 0.598  0.764 #> E[Y(1)|0]    0.733 0.655  0.803 #> RR[0]        1.061 0.919  1.236 #> E[Y(0)|1]    0.668 0.547  0.768 #> E[Y(1)|1]    0.848 0.694  0.942 #> RR[1]        1.270 0.988  1.593"},{"path":"/articles/clarify.html","id":"sim_adrf-average-dose-response-functions","dir":"Articles","previous_headings":"Wrappers for sim_apply(): sim_setx(), sim_ame(), and sim_adrf()","what":"sim_adrf(): average dose-response functions","title":"`clarify`: Simulation-Based Inference for Regression Models","text":"dose-response function individual relationship set value continuous focal predictor expected outcome. average dose-response function (ADRF) average dose-response functions across units. Essentially, function relates value predictor corresponding AAP outcome, average value outcome units set level predictor. ADRFs can used provide additional detail effect continuous predictor beyond single AME. related quantity average marginal effect function (AMEF), describes relationship continuous focal predictor AME level predictor. , rather describing outcome changes function predictor, describes effect predictor outcome changes function predictor. essentially derivative ADRF can used identify points along ADRF predictor effect. ADRF AMEF can computed using sim_adrf(). arguments : sim – clarify_sim object; output call sim(). var – name focal variable compute ADRF AMEF. subset – logical vector, evaluated original dataset used fit model, defining subset units ARDF AMEF computed. – name one variables ADRF AMEF computed within subgroups. Can supplied character vector variable names one-sided formula. contrast – either \"adrf\" \"amef\" request ADRF AMEF, respectively. default compute ADRF. – values focal predictor compute ADRF AMEF. vector values focal predictor can take . unspecified, vector n (see ) equally-spaced values minimum maximum value predictor used. typically used quantities desired subset values focal predictor. n – unspecified, number points along range focal predictor compute ADRF AMEF. yields smoother functions, take longer require memory. default 21. outcome – string containing name outcome interest multivariate (multiple outcome) model supplied sim() outcome category interest multinomial model supplied sim(). univariate (single outcome) binary outcomes, ignored. type – string containing type predicted value return. cases, can left unspecified request predictions scale outcome. eps – value observed values variable named var changed continuous compute AMEF. usually need specified. verbose – whether display progress bar. cl – argument controls parallel processing, can number cores use cluster object resulting parallel::makeCluster(). , consider age (just demonstration; analysis valid interpretation) compute ADRF AMEF age outcome. examine ages 18 50, even though range age goes slightly beyond values. First, compute ADRF age, examines outcome vary average one set unit’s value age value 18 50 (use even ages speed computation). can plot ADRF using plot().  plot, can see age increases, expected outcome decreases. can also examine AAPs requested ages using summary(), display estimated AAPs default, request just first 4 (ages 18 24): Next compute AMEF, effect age level age. can plot AMEF using plot():  plot, can see AME age decreases slightly mostly constant across values age, uncertainty intervals AMEs consistently exclude 0.","code":"sim_adrf(sim = , var = , subset = , by = , contrast = , at = ,          n = , outcome = , type = , eps = , verbose = , cl = ) age_seq <- seq(18, 50, by = 2)  est8 <- sim_adrf(s,                  var = \"age\",                  contrast = \"adrf\",                  at = age_seq,                  verbose = FALSE) plot(est8) summary(est8, parm = 1:4) #>          Estimate 2.5 % 97.5 % #> E[Y(18)]    0.821 0.768  0.855 #> E[Y(20)]    0.811 0.763  0.843 #> E[Y(22)]    0.800 0.756  0.830 #> E[Y(24)]    0.788 0.748  0.817 est9 <- sim_adrf(s,                  var = \"age\",                  contrast = \"amef\",                  at = age_seq,                  verbose = FALSE) plot(est9)"},{"path":"/articles/clarify.html","id":"transforming-and-combining-estimates","dir":"Articles","previous_headings":"","what":"Transforming and combining estimates","title":"`clarify`: Simulation-Based Inference for Regression Models","text":"Often, quantities interest just outputs functions , comparisons . example, test moderation treatment effect, may want compare AMEs multiple groups defined moderator. , might interested effect described using different effect measure one originally produced; example, may decide want risk difference AME computing risk ratio AME. functions transform() cbind() allow users transform quantities single clarify_est object combine two clarify_est objects. essential computing quantities derived derived quantities computed sim_*() functions.","code":""},{"path":"/articles/clarify.html","id":"transform","dir":"Articles","previous_headings":"Transforming and combining estimates","what":"transform()","title":"`clarify`: Simulation-Based Inference for Regression Models","text":"transform() generic function R typically used create new variable data frame function columns. example, compute binary outcome used model, run following5: Similarly, compute derived transformed quantity clarify_est object, can use transform(). , compute risk difference AME treat; previously, used sim_ame() compute AAPs risk ratio. Note used tics (`) around names AAPs; necessary contain special characters like parentheses brackets. alternative use shortcut names .b#, # replaced number (e.g., .b1, .b2, etc.) corresponding index quantity referenced. example, E[Y(1)]andE[Y(0)] second first computed quantities, respectively, code replaced yield identical results6. run summary() output, new quantity, named “RD”, displayed along estimates. also set null value quantity. mentioned previously, one benefit using simulation-based inference p-values computed inverting confidence intervals p-values testing hypothesis risk difference risk ratio (effect measure comparing pair values) always exactly align, thereby ensuring inference depend effect measure used. contrast, Wald-type inference (based either simulation-derived delta method standard error) invariant transformations quantity interest. value computed called sim_ame() clarify_sim object requested risk difference using contrast = \"diff\"; using transform() saves time AAPs already computed stored clarify_est object. can use transform() along variable sim_ame() compute contrast quantities computed within subgroup married. Previously used compute risk ratio ATT within levels married; compute ratio risk ratios assess presence effect modification. RR[1]/RR[0] contains ratio risk ratios married = 1 married = 0. also include test whether risk ratios ratio differ 1, equivalent testing whether risk ratios differ across levels married.","code":"lalonde <- transform(lalonde,                      re78_0 = ifelse(re78 == 0, 1, 0)) est6 <- transform(est6,                   RD = `E[Y(1)]` - `E[Y(0)]`) est6 <- transform(est6,                   RD = .b2 - .b1) summary(est6, null = c(`RR` = 1, `RD` = 0)) #>         Estimate   2.5 %  97.5 % P-value #> E[Y(0)]   0.6866  0.6029  0.7572       . #> E[Y(1)]   0.7551  0.6887  0.8136       . #> RR        1.0998  0.9657  1.2760    0.15 #> RD        0.0685 -0.0263  0.1656    0.15 est6b |>   transform(`RR[1]/RR[0]` = `RR[1]` / `RR[0]`) |>   summary(parm = c(\"RR[0]\", \"RR[1]\", \"RR[1]/RR[0]\"),           null = 1) #>             Estimate 2.5 % 97.5 % P-value   #> RR[0]          1.061 0.919  1.236    0.43   #> RR[1]          1.270 0.988  1.593    0.07 . #> RR[1]/RR[0]    1.196 0.905  1.506    0.18   #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"/articles/clarify.html","id":"cbind","dir":"Articles","previous_headings":"Transforming and combining estimates","what":"cbind()","title":"`clarify`: Simulation-Based Inference for Regression Models","text":"cbind() another generic R function typically used combine two datasets columnwise (.e., widen dataset). clarify, cbind() can used combine two clarify_est objects estimates can examined jointly possible compare directly. example, compute AMEs two subgroups using subset wanted compare , call sim_ame() twice, one subset (though practice effective use ; just illustration), demonstrated : , computed risk difference subgroups race = \"black\" race = \"hispan\". wanted compare risk differences, combine compute new quantity equal difference. . First, need rename quantities object overlap; can using names(), special method clarify_est objects. Next, use cbind() bind objects together. Finally, can use transform() compute difference risk differences: Importantly, cbind() can used join together clarify_est objects computed using simulated coefficients (.e., resulting call sim()). preserves covariance among estimated quantities, critical maintaining valid inference. , sim() called per model, derived quantities computed using output.","code":"# AME of treat with race = \"black\" est10b <- sim_ame(s, var = \"treat\", subset = race == \"black\",                   contrast = \"diff\", verbose = FALSE) summary(est10b) #>         Estimate   2.5 %  97.5 % #> E[Y(0)]   0.6677  0.5715  0.7484 #> E[Y(1)]   0.7439  0.6714  0.8058 #> Diff      0.0762 -0.0209  0.1768  # AME of treat with race = \"hispan\" est10h <- sim_ame(s, var = \"treat\", subset = race == \"hispan\",                   contrast = \"diff\", verbose = FALSE) summary(est10h) #>         Estimate    2.5 %   97.5 % #> E[Y(0)]  0.82664  0.71804  0.89555 #> E[Y(1)]  0.89707  0.79463  0.95146 #> Diff     0.07044 -0.00533  0.14530 names(est10b) <- paste(names(est10b), \"b\", sep = \"_\") names(est10h) <- paste(names(est10h), \"h\", sep = \"_\") est10 <- cbind(est10b, est10h) summary(est10) #>           Estimate    2.5 %   97.5 % #> E[Y(0)]_b  0.66770  0.57151  0.74836 #> E[Y(1)]_b  0.74389  0.67143  0.80581 #> Diff_b     0.07619 -0.02086  0.17679 #> E[Y(0)]_h  0.82664  0.71804  0.89555 #> E[Y(1)]_h  0.89707  0.79463  0.95146 #> Diff_h     0.07044 -0.00533  0.14530 est10 <- transform(est10,                    `Dh - Db` = Diff_h - Diff_b) summary(est10, parm = \"Dh - Db\") #>         Estimate    2.5 %   97.5 % #> Dh - Db -0.00575 -0.06782  0.04043"},{"path":"/articles/clarify.html","id":"using-clarify-with-multiply-imputed-data","dir":"Articles","previous_headings":"","what":"Using clarify with multiply imputed data","title":"`clarify`: Simulation-Based Inference for Regression Models","text":"Multiple imputation popular method estimating quantities interest presence missing data involves creating multiple versions original dataset missing values imputed estimates imputation model. Simulation-based inference multiply imputed data relatively straightforward. Simulated coefficients drawn model estimated imputed dataset separately, simulated coefficients pooled single set simulated coefficients. Bayesian terms, considered “mixing draws” recommended approach Bayesian analysis multiply imputed data (Zhou Reiter 2010). Using clarify multiply imputed data simple. Rather using sim(), use function misim(). misim() functions just like sim() except takes list model fits (.e., containing model fit imputed dataset) object containing list (e.g., mira object mice::() mimira object MatchThem::()). misim() simulates coefficient distributions within imputed dataset appends together form single combined set coefficient draws. sim_apply() wrappers accept output misim() compute desired quantity using set coefficients. functions rely using dataset (e.g., sim_ame(), averages predicted outcomes across units dataset used fit model), automatically know associate given coefficient draw imputed dataset used fit model produced draw. user-written functions supplied FUN argument sim_apply(), important correctly extract dataset model fit. demonstrated . final estimates quantity interest computed mean estimates computed imputed dataset (.e., using original coefficients, simulated ones), quantity computed using standard pooling rules. always valid noncollapsible estimates, like ratios, care taken ensure mean resulting estimates valid interpretation (related transformation-induced bias described Rainey (2017)). arguments misim() follows: fitlist – list model fits accepted object containing (e.g., mira object mice::()) n – number simulations run imputed dataset. default 1000, fewer can used total number simulated quantities m * n, m number imputed datasets. vcov, coefs, dist – sim(), except list arguments can supplied applied imputed dataset. illustrate using misim() sim_apply() multiply imputed data. use africa dataset Amelia package. function applying imputed dataset one computes AME infl. (run analysis afterward using sim_ame().) Note sim_apply() “knows” imputation produced set simulated coefficients, using insight::get_predictors() fit supplied sim_fun() use right dataset. Care taken analyses restrict imputed dataset different way (e.g. matching caliper one), resulting imputations may refer specific target population mixing draws may invalid. , can use sim_ame(): get results, expected. Note misim() compatible model fit objects mice, Amelia, MatchThem, package produces list model fit objects corresponding output model fit imputed dataset.","code":"misim(fitlist = , n = , vcov = , coefs = , dist = ) library(Amelia) data(\"africa\", package = \"Amelia\")  # Multiple imputation a.out <- amelia(x = africa, m = 10, cs = \"country\",                 ts = \"year\", logs = \"gdp_pc\", p2s = 0)  # Fit model to each dataset model.list <- with(a.out, lm(gdp_pc ~ infl * trade))  # Simulate coefficients, 100 draws per imputation si <- misim(model.list, n = 100)  si #> A `clarify_misim` object #>  - 4 coefficients, 10 imputations with 100 simulated values each #>  - sampled distributions: multivariate t(116) sim_fun <- function(fit) {   #Extract the original dataset using get_predictors()   X <- insight::get_predictors(fit)      p0 <- predict(fit)      #Predictions after perturbing infl slightly   p1 <- predict(fit, newdata = transform(X, infl = infl + 1e-5))     c(AME = mean((p1 - p0) / 1e-5)) }  est_mi <- sim_apply(si, FUN = sim_fun, verbose = FALSE)  summary(est_mi) #>     Estimate 2.5 % 97.5 % #> AME    -5.76 -9.39  -2.38 est_mi2 <- sim_ame(si, var = \"infl\", verbose = FALSE)  summary(est_mi2) #>               Estimate 2.5 % 97.5 % #> E[dY/d(infl)]    -5.76 -9.39  -2.38"},{"path":"/articles/clarify.html","id":"comparison-to-other-packages","dir":"Articles","previous_headings":"","what":"Comparison to other packages","title":"`clarify`: Simulation-Based Inference for Regression Models","text":"Several packages offer methods computing interpretable quantities form regression models, including emmeans (Lenth 2024), margins (Leeper 2024), modelbased (Makowski et al. 2020), marginaleffects (Arel-Bundock, Greifer, Heiss 2024). Many quantities computed packages can also computed clarify, primary difference clarify uses simulation-based inference rather delta method-based inference. marginaleffects offers similar functionality clarify, clarify depends functionality provided marginaleffects accommodate wide variety regression models. marginaleffects also offers simulation-based inference using marginaleffects::inferences() support arbitrary user-specified post-estimation functions using marginaleffects::hypotheses(). However, clarify marignalefefcts differ several ways. largest difference clarify supports iterative building complex hypotheses transform() method, quickly computes new quantities transformation existing computed quantities, whereas marginaleffects supports single transformation , version 0.20.0, use simulation-based inference quantities. clarify’s focus simulation, provides functionality directly aimed improving simulation-based inference, including plots view distributions simulated values support parallel processing. clarify also provides support simulation-based inference multiply imputed data, require special pooling rules. areas cases marginaleffects may better choice clarify differences packages little consequence. marginaleffects focuses providing complete framework post-estimation using model predictions, whereas clarify primarily focused supporting user-defined functions, commonly used estimators offered convenience. cases delta method acceptable approximation (e.g., quantities computed linear models quantities known approximately Normally distributed finite samples), using delta method marginaleffects much faster, accurate, replicable simulation-based inference clarify provides. quantities easily computed marginaleffects support simulation-based inference marginaleffects::inferences(), using marginaleffects can provide familiar flexible syntax clarify might offer. Ultimately, user use package supports desired syntax mode inference.","code":""},{"path":"/articles/clarify.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"`clarify`: Simulation-Based Inference for Regression Models","text":"clarify provides functionality facilitate simulation-based inference deriving quantities regression models. framework provides alternative delta method can yield confidence intervals closer nominal coverage quantities interest. claim simulation-based inference universally preferred delta method-based inference, cases can retain advantageous properties, hope availability methods clarify encourages additional research properties can realized facilitates empirical work takes advantages properties.","code":""},{"path":[]},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Noah Greifer. Author, maintainer. Steven Worthington. Author. Stefano Iacus. Author. Gary King. Author.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Greifer N, Worthington S, Iacus S, King G (2025). “clarify: Simulation-Based Inference Regression Models.” R Journal, 16(2), 154–174. doi:10.32614/RJ-2024-015.","code":"@Article{,   title = {clarify: Simulation-Based Inference for Regression Models},   author = {Noah Greifer and Steven Worthington and Stefano Iacus and Gary King},   journal = {The R Journal},   year = {2025},   volume = {16},   number = {2},   pages = {154--174},   doi = {10.32614/RJ-2024-015}, }"},{"path":"/index.html","id":"clarify-simulation-based-inference-for-regression-models","dir":"","previous_headings":"","what":"Simulation-Based Inference for Regression Models","title":"Simulation-Based Inference for Regression Models","text":"clarify implements simulation-based inference computing functions model parameters, average marginal effects predictions representative values predictors. See clarify website documentation examples. clarify designed replicate expand functionality previously provided Zelig package.","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Simulation-Based Inference for Regression Models","text":"clarify can installed CRAN using can install development version clarify GitHub ","code":"install.packages(\"clarify\") install.packages(\"remotes\") remotes::install_github(\"iqss/clarify\")"},{"path":"/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Simulation-Based Inference for Regression Models","text":"example performing g-computation average treatment effect treated (ATT) logistic regression compute average causal risk ratio confidence interval. First load data (case lalonde dataset MatchIt) fit logistic regression using functions outside clarify: Next, estimate ATT risk ratio, simulate coefficients implied distribution compute effects interest simulation, yielding distribution estimates can summarize use inference:  , provide information framework clarify uses examples. complete vignette, see vignette(\"clarify\").","code":"library(clarify)  data(\"lalonde\", package = \"MatchIt\")  # Fit the model fit <- glm(I(re78 > 0) ~ treat + age + educ + race + married +              nodegree + re74 + re75,            data = lalonde, family = binomial) # Simulate coefficients from a multivariate normal distribution set.seed(123) sim_coefs <- sim(fit)  # Marginal risk ratio ATT, simulation-based sim_est <- sim_ame(sim_coefs,                    var = \"treat\",                    subset = treat == 1,                    contrast = \"RR\",                    verbose = FALSE)  sim_est #> A `clarify_est` object (from `sim_ame()`) #>  - Average adjusted predictions for `treat` #>  - 1000 simulated values #>  - 3 quantities estimated:                #>  E[Y(0)] 0.6831 #>  E[Y(1)] 0.7568 #>  RR      1.1078  # View the estimates, confidence intervals, and p-values summary(sim_est, null = c(`RR` = 1)) #>         Estimate 2.5 % 97.5 % P-value #> E[Y(0)]    0.683 0.592  0.754       . #> E[Y(1)]    0.757 0.693  0.807       . #> RR         1.108 0.979  1.289    0.12  # Plot the resulting sampling distributions plot(sim_est)"},{"path":"/index.html","id":"introduction","dir":"","previous_headings":"","what":"Introduction","title":"Simulation-Based Inference for Regression Models","text":"Simulation-based inference alternative delta method bootstrapping performing inference quantities functions model parameters. involves simulating model coefficients multivariate distribution using estimated values covariance single model fit original data, computing quantities interest set model coefficients, performing inference using resulting distribution estimates sampling distribution. Confidence intervals can computed using percentiles resulting sampling distribution, p-values can computed inverting confidence intervals. Alternatively, resulting sampling distribution normally distributed, standard error can estimated standard deviation estimates normal-theory Wald confidence intervals p-values can computed. methodology simulation-based inference explained King, Tomz, Wittenberg (2000). clarify designed provide simple, general interface simulation-based inference includes convenience functions perform common tasks like computing average marginal effects. primary functions clarify sim(), sim_apply(), summary(), plot(). work together create simple workflow simulation-based inference. sim() simulates model parameters fitted model sim_apply() applies estimator simulated coefficients, original object new coefficients inserted summary() produces confidence intervals p-values resulting estimates plot() produces plots simulated sampling distribution resulting estimates also wrappers sim_apply() performing common operations: sim_ame() computes average marginal effect variable, mirroring marginaleffects::avg_predictions() marginaleffects::avg_slopes(); sim_setx() computes predictions typical values covariates differences , mirroring Zelig::setx() Zelig::setx1(); sim_adrf() computes average dose-response functions. clarify also offers support models fit multiply imputed data misim() function. example , used sim_ame() compute ATT, also done manually using sim_apply(), demonstrated :  plot simulated sampling distribution indicates sampling distribution risk ratio normally distributed around estimate, indicating delta method may poor approximation asymmetric confidence intervals produced using simulation may valid. Note estimates computed original model coefficients; distribution used computing confidence intervals, line recommendations Rainey (2023). want compute risk difference, can using transform() already-produced output: can also use clarify compute predictions first differences set typical values predictors, mimicking functionality Zelig’s setx() setx1() functions, using sim_setx():  See vignette(\"Zelig\", package = \"clarify\") examples translating Zelig-based workflow one uses clarify estimate quantities interest. clarify offers parallel processing estimation functions speed computation. Functionality also available analysis models fit multiply imputed data. See vignette(\"clarify\") details.","code":"# Write a function that computes the g-computation estimate for the ATT ATT_fun <- function(fit) {   d <- subset(lalonde, treat == 1)   d$treat <- 1   p1 <- mean(predict(fit, newdata = d, type = \"response\"))   d$treat <- 0   p0 <- mean(predict(fit, newdata = d, type = \"response\"))   c(`E[Y(0)]` = p0, `E[Y(1)]` = p1, `RR` = p1 / p0) }  # Apply that function to the simulated coefficient sim_est <- sim_apply(sim_coefs, ATT_fun, verbose = FALSE)  sim_est #> A `clarify_est` object (from `sim_apply()`) #>  - 1000 simulated values #>  - 3 quantities estimated:                #>  E[Y(0)] 0.6831 #>  E[Y(1)] 0.7568 #>  RR      1.1078  # View the estimates, confidence intervals, and p-values; # they are the same as when using sim_ame() above summary(sim_est, null = c(`RR` = 1)) #>         Estimate 2.5 % 97.5 % P-value #> E[Y(0)]    0.683 0.592  0.754       . #> E[Y(1)]    0.757 0.693  0.807       . #> RR         1.108 0.979  1.289    0.12  # Plot the resulting sampling distributions plot(sim_est, reference = TRUE, ci = FALSE) #Transform estimates into new quantities of interest sim_est <- transform(sim_est, `RD` = `E[Y(1)]` - `E[Y(0)]`) summary(sim_est, null = c(`RR` = 1, `RD` = 0)) #>         Estimate   2.5 %  97.5 % P-value #> E[Y(0)]   0.6831  0.5925  0.7543       . #> E[Y(1)]   0.7568  0.6934  0.8067       . #> RR        1.1078  0.9789  1.2888    0.12 #> RD        0.0737 -0.0155  0.1742    0.12 # Predictions across age and treat at typical values # of the other predictors sim_est <- sim_setx(sim_coefs,                     x = list(age = 20:50, treat = 0:1),                     verbose = FALSE)  #Plot of predicted values across age for each value of treat plot(sim_est)"},{"path":"/index.html","id":"references","dir":"","previous_headings":"","what":"References","title":"Simulation-Based Inference for Regression Models","text":"King, G., Tomz, M., & Wittenberg, J. (2000). Making Statistical Analyses: Improving Interpretation Presentation. American Journal Political Science, 44(2), 347–361. https://doi.org/10.2307/2669316 Rainey, C. (2023). careful consideration CLARIFY: Simulation-induced bias point estimates quantities interest. Political Science Research Methods, 1–10. https://doi.org/10.1017/psrm.2023.8","code":""},{"path":"/reference/clarify-package.html","id":null,"dir":"Reference","previous_headings":"","what":"clarify: Simulation-Based Inference for Regression Models — clarify-package","title":"clarify: Simulation-Based Inference for Regression Models — clarify-package","text":"Performs simulation-based inference alternative delta method obtaining valid confidence intervals p-values regression post-estimation quantities, average marginal effects predictions representative values. framework simulation-based inference especially useful resulting quantity normally distributed delta method approximation fails. methodology described Greifer, et al. (2025) doi:10.32614/RJ-2024-015 . 'clarify' meant replace functionality archived package 'Zelig'; see vignette \"Translating Zelig clarify\" replicating functionality.","code":""},{"path":"/reference/clarify-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"clarify: Simulation-Based Inference for Regression Models — clarify-package","text":"Greifer, N., Worthington, S., Iacus, S., & King, G. (2025). clarify: Simulation-Based Inference Regression Models. R Journal 16(2), 154–174. doi:10.32614/RJ-2024-015","code":""},{"path":[]},{"path":"/reference/clarify-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"clarify: Simulation-Based Inference for Regression Models — clarify-package","text":"Maintainer: Noah Greifer ngreifer@iq.harvard.edu (ORCID) Authors: Steven Worthington sworthington@iq.harvard.edu (ORCID) Stefano Iacus siacus@iq.harvard.edu (ORCID) Gary King king@harvard.edu (ORCID)","code":""},{"path":"/reference/misim.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate model coefficients after multiple imputation — misim","title":"Simulate model coefficients after multiple imputation — misim","text":"misim() simulates model parameters multivariate normal t distributions multiple imputation used sim_apply() calculate quantities interest.","code":""},{"path":"/reference/misim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate model coefficients after multiple imputation — misim","text":"","code":"misim(fitlist, n = 1000, vcov = NULL, coefs = NULL, dist = NULL)"},{"path":"/reference/misim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate model coefficients after multiple imputation — misim","text":"fitlist list model fits, one imputed dataset, mira object (output call () applied mids object mice). n number simulations run imputed dataset; default 1000. always better resulting calculations take longer. vcov square covariance matrix coefficient covariance estimates, function use extract fit, list thereof element imputed dataset. default, uses stats::vcov() insight::get_varcov() work. coefs vector coefficient estimates, function use extract fit, list thereof element imputed dataset. default, uses stats::coef() insight::get_parameters() work. dist character vector containing name multivariate distribution(s) use draw simulated coefficients. one \"normal\" (multivariate normal distribution) \"t_{#}\" (multivariate t distribution), {#} corresponds desired degrees freedom (e.g., \"t_100\"). NULL, right distributions use determined based heuristics; see sim() details.","code":""},{"path":"/reference/misim.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate model coefficients after multiple imputation — misim","text":"clarify_misim object, inherits clarify_sim following components: sim.coefs matrix containing simulated coefficients column coefficient row simulation imputation coefs matrix containing original coefficients extracted fitlist supplied coefs, row per imputation. fit list model fits supplied fitlist imp identifier imputed dataset set simulated coefficients corresponds . \"dist\" attribute contains \"normal\" coefficients sampled multivariate normal distribution \"t({df})\" sampled multivariate t distribution. \"clarify_hash\" attribute contains unique hash generated rlang::hash().","code":""},{"path":"/reference/misim.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulate model coefficients after multiple imputation — misim","text":"misim() essentially combines multiple sim() calls applied list model fits, fit imputed dataset, single combined pool simulated coefficients. simulation-based inference used multiply imputed data, many imputations required; see Zhou Reiter (2010).","code":""},{"path":"/reference/misim.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Simulate model coefficients after multiple imputation — misim","text":"Zhou, X., & Reiter, J. P. (2010). Note Bayesian Inference Multiple Imputation. American Statistician, 64(2), 159–163. doi:10.1198/tast.2010.09109","code":""},{"path":[]},{"path":"/reference/misim.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate model coefficients after multiple imputation — misim","text":"","code":"data(\"africa\", package = \"Amelia\")  # Multiple imputation using Amelia a.out <- Amelia::amelia(x = africa, m = 10,                         cs = \"country\",                         ts = \"year\", logs = \"gdp_pc\",                         p2s = 0)  fits <- with(a.out, lm(gdp_pc ~ infl * trade))  # Simulate coefficients s <- misim(fits) s #> A `clarify_misim` object #>  - 4 coefficients, 10 imputations with 1000 simulated values each #>  - sampled distributions: multivariate t(116)"},{"path":"/reference/plot.clarify_adrf.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot marginal predictions from sim_adrf() — plot.clarify_adrf","title":"Plot marginal predictions from sim_adrf() — plot.clarify_adrf","text":"plot.clarify_adrf() plots output sim_adrf(). average dose-response function (ADRF, requested contrast = \"adrf\" sim_adrf()), plot average marginal mean outcome requested values focal predictor; average marginal effects function (AMEF, requested contrast = \"amef\" sim_adrf()), plot instantaneous average marginal effect focal predictor outcome requested values focal predictor.","code":""},{"path":"/reference/plot.clarify_adrf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot marginal predictions from sim_adrf() — plot.clarify_adrf","text":"","code":"# S3 method for class 'clarify_adrf' plot(   x,   ci = TRUE,   level = 0.95,   method = \"quantile\",   baseline = NULL,   color = \"black\",   simultaneous = FALSE,   ... )"},{"path":"/reference/plot.clarify_adrf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot marginal predictions from sim_adrf() — plot.clarify_adrf","text":"x clarify_adrf object resulting call sim_adrf(). ci logical; whether display confidence bands estimates. Default TRUE. level confidence level desired. Default .95 95% confidence intervals. method method used compute confidence bands. Can \"wald\" use Normal approximation \"quantile\" use simulated sampling distribution (default). See summary.clarify_est() details. Abbreviations allowed. baseline logical; whether include horizontal line y = 0 plot. Default FALSE ADRF (since 0 might range outcome) TRUE AMEF. color color line confidence band plot. simultaneous logical; whether confidence bands simultaneous (.e., nominal coverage whole effect curve); default FALSE, TRUE recommended. See Details summary.clarify_est() details. ... plot(), arguments passed ggplot2::geom_density().","code":""},{"path":"/reference/plot.clarify_adrf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot marginal predictions from sim_adrf() — plot.clarify_adrf","text":"ggplot object.","code":""},{"path":"/reference/plot.clarify_adrf.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot marginal predictions from sim_adrf() — plot.clarify_adrf","text":"plots produced using ggplot2::geom_line() ggplot2::geom_ribbon(). confidence bands interpreted pointwise (.e., account simultaneous inference) unless simultaneous = TRUE.","code":""},{"path":[]},{"path":"/reference/plot.clarify_adrf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot marginal predictions from sim_adrf() — plot.clarify_adrf","text":"","code":"## See help(\"sim_adrf\") for examples"},{"path":"/reference/plot.clarify_setx.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot marginal predictions from sim_setx() — plot.clarify_setx","title":"Plot marginal predictions from sim_setx() — plot.clarify_setx","text":"plot.clarify_sext() plots output sim_setx(), providing graphics similar plot.clarify_est() features specifically plot marginal predictions. continues predictors, plot marginal predictions confidence bands across levels predictor. Otherwise, plot simulated sampling distribution marginal predictions.","code":""},{"path":"/reference/plot.clarify_setx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot marginal predictions from sim_setx() — plot.clarify_setx","text":"","code":"# S3 method for class 'clarify_setx' plot(   x,   var = NULL,   ci = TRUE,   level = 0.95,   method = \"quantile\",   reference = FALSE,   simultaneous = FALSE,   ... )"},{"path":"/reference/plot.clarify_setx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot marginal predictions from sim_setx() — plot.clarify_setx","text":"x clarify_est object resulting call sim_setx(). var name focal varying predictor, .e., variable x-axis plot. variables varying set values used color resulting plot. See Details. Ignored predictors vary one predictor varies reference grid x1 specified sim_setx(). set, use predictor greatest number unique values specified reference grid. ci logical; whether display confidence intervals bands estimates. Default TRUE. level confidence level desired. Default .95 95% confidence intervals. method method used compute confidence intervals bands. Can \"wald\" use Normal approximation \"quantile\" use simulated sampling distribution (default). See summary.clarify_est() details. Abbreviations allowed. reference logical; whether overlay normal density reference distribution plots. Default FALSE. Ignored variables focal varying predictor vary. simultaneous logical; whether confidence bands simultaneous (.e., nominal coverage whole effect curve); default FALSE, TRUE recommended. See Details summary.clarify_est() details. ... plot(), arguments passed ggplot2::geom_density().","code":""},{"path":"/reference/plot.clarify_setx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot marginal predictions from sim_setx() — plot.clarify_setx","text":"ggplot object.","code":""},{"path":"/reference/plot.clarify_setx.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot marginal predictions from sim_setx() — plot.clarify_setx","text":"plot() creates one two kinds plots depending reference grid specified call sim_setx() var set . focal varying predictor (.e., one set var) numeric takes three unique values reference grid, produced plot line graph displaying value marginal prediction (denoted E[Y|X]) across values focal varying predictor, confidence bands displayed ci = TRUE. predictors also vary, lines different values displayed different colors. plots produced using ggplot2::geom_line() ggplot2::geom_ribbon() focal varying predictor factor character takes two fewer values reference grid, produced plot density plot simulated predictions, similar plot resulting plot.clarify_est(). variables vary, densities different values displayed different colors. plots produced using ggplot2::geom_density(). Marginal predictions identified corresponding levels predictors vary. user keep track whether non-varying predictors set specified automatically set \"typical\" levels.","code":""},{"path":[]},{"path":"/reference/plot.clarify_setx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot marginal predictions from sim_setx() — plot.clarify_setx","text":"","code":"## See help(\"sim_setx\") for examples"},{"path":"/reference/sim.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate model parameters — sim","title":"Simulate model parameters — sim","text":"sim() simulates model parameters multivariate normal t distribution used sim_apply() calculate quantities interest.","code":""},{"path":"/reference/sim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate model parameters — sim","text":"","code":"sim(fit, n = 1000L, vcov = NULL, coefs = NULL, dist = NULL)"},{"path":"/reference/sim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate model parameters — sim","text":"fit model fit, output call lm() glm(). Can left unspecified coefs vcov functions. n number simulations run; default 1000. always better resulting calculations take longer. vcov either square covariance matrix coefficient covariance estimates function use extract fit. default, uses stats::vcov() insight::get_varcov() work. coefs either vector coefficient estimates function use extract fit. default, uses stats::coef() insight::get_parameters() work. dist string containing name multivariate distribution use draw simulated coefficients. one \"normal\" (multivariate normal distribution) \"t({#})\" (multivariate t distribution), {#} corresponds desired degrees freedom (e.g., \"t(100)\"). NULL, right distribution use determined based heuristics; see Details.","code":""},{"path":"/reference/sim.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate model parameters — sim","text":"clarify_sim object, following components: sim.coefs matrix containing simulated coefficients column coefficient row simulation coefs original coefficients extracted fit supplied coefs. vcov covariance matrix coefficients extracted fit supplied vcov fit original model fit supplied fit \"dist\" attribute contains \"normal\" coefficients sampled multivariate normal distribution \"t(df)\" sampled multivariate t distribution. \"clarify_hash\" attribute contains unique hash generated rlang::hash().","code":""},{"path":"/reference/sim.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulate model parameters — sim","text":"dist NULL, sim() samples multivariate normal t distribution depending degrees freedom extracted insight::get_df(., type = \"wald\"). Inf, normal distribution used; otherwise, t-distribution returned degrees freedom used. Models supported insight use normal distribution.","code":""},{"path":[]},{"path":"/reference/sim.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate model parameters — sim","text":"","code":"data(\"lalonde\", package = \"MatchIt\") fit <- lm(re78 ~ treat * (age + race + nodegree + re74),           data = lalonde)  # Simulate coefficients s <- sim(fit) s #> A `clarify_sim` object #>  - 12 coefficients, 1000 simulated values #>  - sampled distribution: multivariate t(602) #>  - original fitting function call: #>  #> lm(formula = re78 ~ treat * (age + race + nodegree + re74), data = lalonde)  ## Could also use a robust covariance matrix, e.g., s <- sim(fit, vcov = \"HC3\")  # Simulated coefficients assuming a normal distribution # for coefficients; default for `lm` objects is a t- # distribution s <- sim(fit, dist = \"normal\") s #> A `clarify_sim` object #>  - 12 coefficients, 1000 simulated values #>  - sampled distribution: multivariate normal #>  - original fitting function call: #>  #> lm(formula = re78 ~ treat * (age + race + nodegree + re74), data = lalonde)"},{"path":"/reference/sim_adrf.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute an average dose-response function — sim_adrf","title":"Compute an average dose-response function — sim_adrf","text":"sim_adrf() wrapper sim_apply() computes average dose-response functions (ADRFs) average marginal effect functions (AMEFs). ADRF describes relationship values focal variable can take expected value outcome units given value variable. AMEF describes relationship values focal variable can take derivative ADRF value.","code":""},{"path":"/reference/sim_adrf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute an average dose-response function — sim_adrf","text":"","code":"sim_adrf(   sim,   var,   subset = NULL,   by = NULL,   contrast = \"adrf\",   at = NULL,   n = 21,   outcome = NULL,   type = NULL,   eps = 1e-05,   verbose = TRUE,   cl = NULL,   ... )  # S3 method for class 'clarify_adrf' print(x, digits = 4L, max.ests = 6L, ...)"},{"path":"/reference/sim_adrf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute an average dose-response function — sim_adrf","text":"sim clarify_sim object; output call sim() misim(). var name variable ADRF AMEF computed. variable must present model supplied sim() must numeric variable taking two unique values. subset optional; vector used subset data used compute ADRF AMEF. evaluated within original dataset used fit model using subset(), nonstandard evaluation allowed. one-sided formula character vector containing names variables stratify estimates. quantity computed within level complete cross variables specified . contrast string naming type quantity produced: \"adrf\" ADRF (default) \"amef\" AMEF. levels variable named var evaluate ADRF AMEF. vector numeric values corresponding possible levels var. NULL, set range slightly lowest observed value var slightly largest value. n = NULL, number points evaluate ADRF AMEF. Default 21. Ignored NULL. outcome string containing name outcome outcome level multivariate (multiple outcomes) multi-category outcomes. Ignored univariate (single outcome) binary outcomes. type string containing type predicted values (e.g., link response). Passed marginaleffects::get_predict() eventually predict() cases. default allowable option depend type model supplied, almost always corresponds response scale (e.g., predicted probabilities binomial models). eps contrast = \"amef\", value shift value var approximate derivative. See Details. verbose logical; whether display text progress bar indicating progress estimated time remaining procedure. Default TRUE. cl cluster object created parallel::makeCluster(), integer indicate number child-processes (integer values ignored Windows) parallel evaluations. See pbapply::pblapply() details. NULL, parallelization take place. ... sim_adrf(), additional arguments passed marginaleffects::get_predict() (eventually predict()) compute predictions. print(), ignored. x clarify_adrf object. digits minimum number significant digits used; passed print.data.frame(). max.ests maximum number estimates display.","code":""},{"path":"/reference/sim_adrf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute an average dose-response function — sim_adrf","text":"clarify_adrf object, inherits clarify_est similar output sim_apply(), additional attributes \"var\" containing variable named var, \"\" containing names variables specified (), \"\" containing values ADRF AMEF evaluated, \"contrast\" containing argument supplied contrast. ADRF, average marginal means named E[Y({v})], {v} replaced values . AMEF, average marginal effects named dY/d({x})|{} {x} replaced var {} replaced values .","code":""},{"path":"/reference/sim_adrf.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute an average dose-response function — sim_adrf","text":"ADRF composed average marginal means across levels focal predictor. level focal predictor, predicted values outcome computed setting value predictor level, values outcome averaged across units sample arrive average marginal mean. Thus, ADRF represent relationship \"dose\" (.e., level focal predictor) average \"response\" (.e., outcome variable). continuous analog average marginal effect computed binary predictor, e.g., using sim_ame(). Although inference can level predictor two levels predictor, typically plot ADRF useful relevant quantity. can requested using plot.clarify_adrf(). AMEF derivative ADRF; call derivative ADRF point \"treatment effect\" (.e., rate outcome changes corresponding small change predictor, \"treatment\"), AMEF function relates size treatment effect level treatment. shape AMEF usually less importance value AMEF level predictor, corresponds size treatment effect corresponding level. AMEF computed computing ADRF level focal predictor specified , shifting predictor value tiny amount (control eps), computing ratio change outcome shift, averaging value across units. quantity related average marginal effect continuous predictor computed sim_ame(), rather average treatment effects across observed levels treatment, AMEF function evaluated possible level treatment. \"tiny amount\" used eps times standard deviation var.","code":""},{"path":[]},{"path":"/reference/sim_adrf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute an average dose-response function — sim_adrf","text":"","code":"data(\"lalonde\", package = \"MatchIt\")  # Fit the model fit <- glm(I(re78 > 0) ~ treat + age + race +              married + re74,            data = lalonde, family = binomial)  # Simulate coefficients set.seed(123) s <- sim(fit, n = 100)  # ADRF for `age` est <- sim_adrf(s, var = \"age\",                 at = seq(15, 55, length.out = 6),                 verbose = FALSE) est #> A `clarify_est` object (from `sim_adrf()`) #>  - Average dose-response function of `age` #>  - 100 simulated values #>  - 6 quantities estimated:                 #>  E[Y(15)] 0.8443 #>  E[Y(23)] 0.7976 #>  E[Y(31)] 0.7416 #>  E[Y(39)] 0.6770 #>  E[Y(47)] 0.6052 #>  E[Y(55)] 0.5290 plot(est)   # AMEF for `age` est <- sim_adrf(s, var = \"age\", contrast = \"amef\",                at = seq(15, 55, length.out = 6),                verbose = FALSE) est #> A `clarify_est` object (from `sim_adrf()`) #>  - Average marginal effect function of `age` #>  - 100 simulated values #>  - 6 quantities estimated:                           #>  E[dY/d(age)|15] -0.005258 #>  E[dY/d(age)|23] -0.006415 #>  E[dY/d(age)|31] -0.007563 #>  E[dY/d(age)|39] -0.008575 #>  E[dY/d(age)|47] -0.009314 #>  E[dY/d(age)|55] -0.009668 summary(est) #>                 Estimate    2.5 %   97.5 % #> E[dY/d(age)|15] -0.00526 -0.00692 -0.00333 #> E[dY/d(age)|23] -0.00641 -0.00904 -0.00364 #> E[dY/d(age)|31] -0.00756 -0.01127 -0.00394 #> E[dY/d(age)|39] -0.00858 -0.01309 -0.00422 #> E[dY/d(age)|47] -0.00931 -0.01410 -0.00447 #> E[dY/d(age)|55] -0.00967 -0.01379 -0.00467 plot(est)   # ADRF for `age` within levels of `married` est <- sim_adrf(s, var = \"age\",                 at = seq(15, 55, length.out = 6),                 by = ~married,                 verbose = FALSE) est #> A `clarify_est` object (from `sim_adrf()`) #>  - Average dose-response function of `age` #>    - within levels of `married` #>  - 100 simulated values #>  - 12 quantities estimated:                   #>  E[Y(15)|0] 0.8215 #>  E[Y(23)|0] 0.7694 #>  E[Y(31)|0] 0.7077 #> --- 6 rows omitted. --- #>  E[Y(39)|1] 0.7324 #>  E[Y(47)|1] 0.6669 #>  E[Y(55)|1] 0.5948 plot(est)   ## Difference between ADRFs est_diff <- est[7:12] - est[1:6] plot(est_diff) + ggplot2::labs(y = \"Diff\")"},{"path":"/reference/sim_ame.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute average marginal effects — sim_ame","title":"Compute average marginal effects — sim_ame","text":"sim_ame() wrapper sim_apply() computes average marginal effects, average effect changing single variable one value another (.e., one category another categorical variables tiny change continuous variables).","code":""},{"path":"/reference/sim_ame.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute average marginal effects — sim_ame","text":"","code":"sim_ame(   sim,   var,   subset = NULL,   by = NULL,   contrast = NULL,   outcome = NULL,   type = NULL,   eps = 1e-05,   verbose = TRUE,   cl = NULL,   ... )  # S3 method for class 'clarify_ame' print(x, digits = 4L, max.ests = 6L, ...)"},{"path":"/reference/sim_ame.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute average marginal effects — sim_ame","text":"sim clarify_sim object; output call sim() misim(). var either names variables marginal effects computed named list containing values variables take. See Details. subset optional; vector used subset data used compute marginal effects. evaluated within original dataset used fit model using subset(), nonstandard evaluation allowed. one-sided formula character vector containing names variables stratify estimates. quantity computed within level complete cross variables specified . contrast string containing name contrast average marginal means variable named var categorical takes two values. Allowed options include \"diff\" difference means (also \"rd\"), \"rr\" risk ratio (also \"irr\"), \"log(rr): log risk ratio (also \"log(irr)\"), \"sr\" survival ratio, \"log(sr): log survival ratio, \"srr\" switch relative risk (also \"grrr\"), \"\" odds ratio, \"log()\" log odds ratio, \"nnt\" number needed treat. options case sensitive, parentheses must included present. outcome string containing name outcome outcome level multivariate (multiple outcomes) multi-category outcomes. Ignored univariate (single outcome) binary outcomes. type string containing type predicted values (e.g., link response). Passed marginaleffects::get_predict() eventually predict() cases. default allowable option depend type model supplied, almost always corresponds response scale (e.g., predicted probabilities binomial models). eps variable named var continuous, value change variable values approximate derivative. See Details. verbose logical; whether display text progress bar indicating progress estimated time remaining procedure. Default TRUE. cl cluster object created parallel::makeCluster(), integer indicate number child-processes (integer values ignored Windows) parallel evaluations. See pbapply::pblapply() details. NULL, parallelization take place. ... sim_ame(), additional arguments passed marginaleffects::get_predict() (eventually predict()) compute predictions. print(), ignored. x clarify_ame object. digits minimum number significant digits used; passed print.data.frame(). max.ests maximum number estimates display.","code":""},{"path":"/reference/sim_ame.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute average marginal effects — sim_ame","text":"clarify_ame object, inherits clarify_est similar output sim_apply(), additional attributes \"var\" containing variable values specified var \"\" containing names variables specified (). average adjusted predictions named E[Y({v})], {v} replaced values variables named var take . average marginal effect continuous var named E[dY/d({x})] {x} replaced var. specified, average adjusted predictions named E[Y({v})|{b}] average marginal effect E[dY/d({x})|{b}] {b} comma-separated list values variables quantity computed. See examples.","code":""},{"path":"/reference/sim_ame.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute average marginal effects — sim_ame","text":"sim_ame() computes average adjusted predictions average marginal effects depending variables named var specified. Canonically, var specified named list value(s) variable set . example, specifying var = list(x1 = 0:1) computes average adjusted predictions setting x1 0 1. Specifying variable's values NULL, e.g., list(x1 = NULL), equivalent requesting average adjusted predictions unique value variable variable binary factor character requests average marginal effect variable otherwise. Specifying unnamed entry list string containing value variable, e.g., list(\"x1\") equivalent specifying list(x1 = NULL). Similarly, supplying vector names variables equivalent specifying list, e.g., var = \"x1\" equivalent var = list(x1 = NULL). Multiple variables can supplied var time set corresponding variables values. values specified directly variables categorical, e.g., list(x1 = 0:1, x2 = c(5, 10)), computes average adjusted predictions combination supplied variables. one variable's values specified NULL variable continuous, average marginal effect variable computed variables set corresponding combinations. example, x2 continuous variable, specifying var = list(x1 = 0:1, x2 = NULL) requests average marginal effect x2 computed first setting x1 0 setting x1 1. average marginal effect can computed one variable time. examples specifications request, assuming x1 binary variable taking values 0 1 x2 continuous variable: list(x1 = 0:1), list(x1 = NULL), list(\"x1\"), \"x1\" – average adjusted predictions setting x1 0 1 list(x2 = NULL), list(\"x2\"), \"x2\" – average marginal effect x2 list(x2 = c(5, 10)) – average adjusted predictions setting x2 5 10 list(x1 = 0:1, x2 = c(5, 10)), list(\"x1\", x2 = c(5, 10)) – average adjusted predictions setting x1 x2 full cross 0, 1 5, 10, respectively (e.g., (0, 5), (0, 10), (1, 5), (1, 10)) list(x1 = 0:1, \"x2\"), list(\"x1\", \"x2\"), c(\"x1\", \"x2\") – average marginal effects x2 setting x1 0 1 average adjusted prediction average predicted outcome value setting units' value variable specified level. (quantity several names, including average potential outcome, average marginal mean, standardized mean). exactly two average adjusted predictions requested, contrast can requested supplying argument contrast (see Effect Measures section ). Contrasts can manually computed using transform() afterward well; required multiple average adjusted predictions requested (.e., single variable supplied var two levels combination multiple variables supplied). marginal effect instantaneous rate change corresponding changing unit's observed value variable tiny amount considering degree predicted outcome changes. ratio change predicted outcome change value variable marginal effect; averaged across sample arrive average marginal effect. \"tiny amount\" used eps times standard deviation focal variable. difference using subset vs. var subset subset data computing requested quantity, whereas var sets corresponding variable given value units. example, using = ~v computes quantity interest separately subset data defined v, whereas setting var = list(., \"v\") computes quantity interest units setting value v unique values. resulting quantities different interpretations. var can used simultaneously.","code":""},{"path":"/reference/sim_ame.html","id":"effect-measures","dir":"Reference","previous_headings":"","what":"Effect measures","title":"Compute average marginal effects — sim_ame","text":"effect measures specified contrast defined . Typically \"diff\" appropriate continuous outcomes \"diff\" \"irr\" appropriate count outcomes; rest appropriate binary outcomes. focal variable two levels, 0 1, outcome Y, average marginal means denoted formulas E[Y(0)] E[Y(1)], respectively. log(.) versions defined taking log() (natural log) corresponding effect measure.","code":""},{"path":[]},{"path":"/reference/sim_ame.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute average marginal effects — sim_ame","text":"","code":"data(\"lalonde\", package = \"MatchIt\")  # Fit the model fit <- glm(I(re78 > 0) ~ treat + age + race +              married + re74,            data = lalonde, family = binomial)  # Simulate coefficients set.seed(123) s <- sim(fit, n = 100)  # Average marginal effect of `age` est <- sim_ame(s, var = \"age\", verbose = FALSE) summary(est) #>              Estimate    2.5 %   97.5 % #> E[dY/d(age)] -0.00695 -0.00990 -0.00379  # Contrast between average adjusted predictions # for `treat` est <- sim_ame(s, var = \"treat\", contrast = \"rr\",                verbose = FALSE) summary(est) #>         Estimate 2.5 % 97.5 % #> E[Y(0)]    0.743 0.695  0.780 #> E[Y(1)]    0.810 0.742  0.847 #> RR         1.090 0.986  1.186  # Average adjusted predictions for `race`; need to follow up # with contrasts for specific levels est <- sim_ame(s, var = \"race\", verbose = FALSE)  est <- transform(est,                  `RR(h,b)` = `E[Y(hispan)]` / `E[Y(black)]`)  summary(est) #>              Estimate 2.5 % 97.5 % #> E[Y(black)]     0.706 0.628  0.778 #> E[Y(hispan)]    0.832 0.717  0.913 #> E[Y(white)]     0.800 0.756  0.841 #> RR(h,b)         1.178 1.011  1.335  # Average adjusted predictions for `treat` within levels of # `married`, first using `subset` and then using `by` est0 <- sim_ame(s, var = \"treat\", subset = married == 0,                 contrast = \"rd\", verbose = FALSE) names(est0) <- paste0(names(est0), \"|married=0\") est1 <- sim_ame(s, var = \"treat\", subset = married == 1,                 contrast = \"rd\", verbose = FALSE) names(est1) <- paste0(names(est1), \"|married=1\")  summary(cbind(est0, est1)) #>                   Estimate   2.5 %  97.5 % #> E[Y(0)]|married=0   0.7241  0.6669  0.7777 #> E[Y(1)]|married=0   0.7952  0.7243  0.8367 #> RD|married=0        0.0711 -0.0102  0.1399 #> E[Y(0)]|married=1   0.7697  0.6972  0.8104 #> E[Y(1)]|married=1   0.8308  0.7256  0.8774 #> RD|married=1        0.0610 -0.0104  0.1232  est <- sim_ame(s, var = \"treat\", by = ~married,                contrast = \"rd\", verbose = FALSE)  est #> A `clarify_est` object (from `sim_ame()`) #>  - Average adjusted predictions for `treat` #>    - within levels of `married` #>  - 100 simulated values #>  - 6 quantities estimated:                  #>  E[Y(0)|0] 0.7241 #>  E[Y(1)|0] 0.7952 #>  RD[0]     0.0711 #>  E[Y(0)|1] 0.7697 #>  E[Y(1)|1] 0.8308 #>  RD[1]     0.0610 summary(est) #>           Estimate   2.5 %  97.5 % #> E[Y(0)|0]   0.7241  0.6669  0.7777 #> E[Y(1)|0]   0.7952  0.7243  0.8367 #> RD[0]       0.0711 -0.0102  0.1399 #> E[Y(0)|1]   0.7697  0.6972  0.8104 #> E[Y(1)|1]   0.8308  0.7256  0.8774 #> RD[1]       0.0610 -0.0104  0.1232  # Average marginal effect of `age` within levels of # married*race est <- sim_ame(s, var = \"age\", by = ~married + race,                verbose = FALSE) est #> A `clarify_est` object (from `sim_ame()`) #>  - Average marginal effect of `age` #>    - within levels of `married` and `race` #>  - 100 simulated values #>  - 6 quantities estimated:                                 #>  E[dY/d(age)|0,black]  -0.007950 #>  E[dY/d(age)|0,hispan] -0.005600 #>  E[dY/d(age)|0,white]  -0.006626 #>  E[dY/d(age)|1,black]  -0.008058 #>  E[dY/d(age)|1,hispan] -0.005498 #>  E[dY/d(age)|1,white]  -0.006304 summary(est, null = 0) #>                       Estimate    2.5 %   97.5 % P-value     #> E[dY/d(age)|0,black]  -0.00795 -0.01174 -0.00425  <2e-16 *** #> E[dY/d(age)|0,hispan] -0.00560 -0.00967 -0.00243  <2e-16 *** #> E[dY/d(age)|0,white]  -0.00663 -0.00947 -0.00343  <2e-16 *** #> E[dY/d(age)|1,black]  -0.00806 -0.01197 -0.00439  <2e-16 *** #> E[dY/d(age)|1,hispan] -0.00550 -0.00941 -0.00239  <2e-16 *** #> E[dY/d(age)|1,white]  -0.00630 -0.00984 -0.00344  <2e-16 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1  # Comparing AMEs between married and unmarried for # each level of `race` est_diff <- est[4:6] - est[1:3] names(est_diff) <- paste0(\"AME_diff|\", levels(lalonde$race)) summary(est_diff) #>                  Estimate     2.5 %    97.5 % #> AME_diff|black  -0.000108 -0.001240  0.001003 #> AME_diff|hispan  0.000102 -0.001207  0.001409 #> AME_diff|white   0.000323 -0.001013  0.001567  # Average adjusted predictions at a combination of `treat` # and `married` est <- sim_ame(s, var = c(\"treat\", \"married\"),                verbose = FALSE) est #> A `clarify_est` object (from `sim_ame()`) #>  - Average adjusted predictions for `treat` and `married` #>  - 100 simulated values #>  - 4 quantities estimated:                  #>  E[Y(0,0)] 0.7374 #>  E[Y(1,0)] 0.8055 #>  E[Y(0,1)] 0.7518 #>  E[Y(1,1)] 0.8171  # Average marginal effect of `age` setting `married` to 1 est <- sim_ame(s, var = list(\"age\", married = 1),                verbose = FALSE)"},{"path":"/reference/sim_apply.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply a function to simulated parameter values — sim_apply","title":"Apply a function to simulated parameter values — sim_apply","text":"sim_apply() applies function produces quantities interest set simulated coefficients produced sim(); calculated quantities form posterior sampling distribution quantities interest. Capabilities available parallelization.","code":""},{"path":"/reference/sim_apply.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply a function to simulated parameter values — sim_apply","text":"","code":"sim_apply(sim, FUN, verbose = TRUE, cl = NULL, ...)  # S3 method for class 'clarify_est' print(x, digits = 4L, max.ests = 6L, ...)"},{"path":"/reference/sim_apply.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply a function to simulated parameter values — sim_apply","text":"sim clarify_sim object; output call sim() misim(). FUN function applied set simulated coefficients. See Details. verbose logical; whether display text progress bar indicating progress estimated time remaining procedure. Default TRUE. cl cluster object created parallel::makeCluster(), integer indicate number child-processes (integer values ignored Windows) parallel evaluations. See pbapply::pblapply() details. NULL, parallelization take place. ... sim_apply(), optional arguments passed FUN. print(), ignored. x clarify_est object. digits minimum number significant digits used; passed print.data.frame(). max.ests maximum number estimates display.","code":""},{"path":"/reference/sim_apply.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply a function to simulated parameter values — sim_apply","text":"clarify_est object, matrix column estimated quantity row simulation. original estimates (FUN applied original coefficients model fit object) stored attribute \"original\". \"sim_hash\" attribute contains simulation hash produced sim().","code":""},{"path":"/reference/sim_apply.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Apply a function to simulated parameter values — sim_apply","text":"sim_apply() applies function, FUN, set simulated coefficients, similar apply(). function return numeric vector containing one estimated quantities. named vector easily keep track meaning estimated quantity. Care taken ensure returned vector length time FUN called. NAs allowed output avoided possible. arguments FUN can specified ways. FUN argument called coefs, simulated set coefficients passed argument, FUN compute return quantity based coefficients (e.g., difference two coefficients one wants test whether two coefficients equal). FUN argument called fit, model fit object type one originally supplied sim() (e.g., lm glm object) passed argument, coefficients fit object replaced simulated coefficients generated sim(), FUN compute return quantity based model fit (e.g., computation based output predict()). neither coefs fit names arguments FUN, model fit object replaced coefficients supplied first argument FUN. custom coefficients supplied sim(), .e., coefs argument sim() left default value, FUN must accept coefs argument warning thrown accepts fit argument. sim_apply() know reconstruct original fit object new coefficients inserted. quantities computed sim_apply() must therefore computed directly coefficients. FUN supplied , simulated values coefficients returned output warning. Set FUN NULL verbose FALSE suppress warning.","code":""},{"path":"/reference/sim_apply.html","id":"sim-apply-with-multiply-imputed-data","dir":"Reference","previous_headings":"","what":"sim_apply() with multiply imputed data","title":"Apply a function to simulated parameter values — sim_apply","text":"using misim() sim_apply() multiply imputed data, coefficients supplied model fit corresponding imputation identifier associated set coefficients, means FUN uses dataset extracted model (e.g., using insight::get_data()), model fit corresponding imputation. original estimates (see Value ) computed mean estimates across imputations using original coefficients averaged across imputations. , first, coefficients estimated models imputed datasets combined form single set pooled coefficients; , imputation, quantities interest computed using pooled coefficients; finally, mean resulting estimates across imputations taken \"original\" estimates. Note procedure valid quantities symmetric sampling distributions, excludes quantities like risk ratios odds ratios, includes log risk ratios log odds ratios. desired quantities can transformed log versions using transform().","code":""},{"path":[]},{"path":"/reference/sim_apply.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply a function to simulated parameter values — sim_apply","text":"","code":"data(\"lalonde\", package = \"MatchIt\") fit <- lm(re78 ~ treat + age + race + nodegree + re74,           data = lalonde) coef(fit) #>   (Intercept)         treat           age    racehispan     racewhite  #>  4596.7282858  1719.6323705    -6.5455292  1605.6558582  1338.9751895  #>      nodegree          re74  #> -1174.9861400     0.3855893   set.seed(123) s <- sim(fit, n = 500)  # Function to compare predicted values for two units # using `fit` argument sim_fun <- function(fit) {   pred1 <- unname(predict(fit, newdata = lalonde[1,]))   pred2 <- unname(predict(fit, newdata = lalonde[2,]))   c(pred1 = pred1, pred2 = pred2) }  est <- sim_apply(s, sim_fun, verbose = FALSE)  # Add difference between predicted values as # additional quantity est <- transform(est, `diff 1-2` = pred1 - pred2)  # Examine estimates and confidence intervals summary(est) #>          Estimate 2.5 % 97.5 % #> pred1        4899  3611   6365 #> pred2        6603  4469   8689 #> diff 1-2    -1704 -3867    651  # Function to compare coefficients using `coefs` # argument sim_fun <- function(coefs) {   setNames(coefs[\"racewhite\"] - coefs[\"racehispan\"],            \"wh - his\") }  est <- sim_apply(s, sim_fun, verbose = FALSE)  # Examine estimates and confidence intervals summary(est) #>          Estimate 2.5 % 97.5 % #> wh - his     -267 -1887   1418  # Another way to do the above: est <- sim_apply(s, FUN = NULL) est <- transform(est,                  `wh - his` = `racewhite` - `racehispan`)  summary(est, parm = \"wh - his\") #>          Estimate 2.5 % 97.5 % #> wh - his     -267 -1887   1418"},{"path":"/reference/sim_setx.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute predictions and first differences at set values — sim_setx","title":"Compute predictions and first differences at set values — sim_setx","text":"sim_setx() wrapper sim_apply() computes predicted values outcome specified values predictors, sometimes called marginal predictions. One can also compute difference two marginal predictions (\"first difference\"). Although function accepted clarify_est objects can used sim_setx() output objects, special plotting function, plot.clarify_setx(), can used plot marginal predictions.","code":""},{"path":"/reference/sim_setx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute predictions and first differences at set values — sim_setx","text":"","code":"sim_setx(   sim,   x = list(),   x1 = list(),   outcome = NULL,   type = NULL,   verbose = TRUE,   cl = NULL,   ... )  # S3 method for class 'clarify_setx' print(x, digits = 4L, max.ests = 6L, ...)"},{"path":"/reference/sim_setx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute predictions and first differences at set values — sim_setx","text":"sim clarify_sim object; output call sim() misim(). x data.frame containing reference grid predictor values named list values predictor take defining reference grid, e.g., list(v1 = 1:4, v2 = c(\"\", \"B\")). omitted predictors fixed \"typical\" value. See Details. x1 specified, x identify single reference unit. print(), clarify_setx object. x1 data.frame named list value predictor take compute first difference predictor combination specified x. x1 can identify single unit. See Details. outcome string containing name outcome outcome level multivariate (multiple outcomes) multi-category outcomes. Ignored univariate (single outcome) binary outcomes. type string containing type predicted values (e.g., link response). Passed marginaleffects::get_predict() eventually predict() cases. default allowable option depend type model supplied, almost always corresponds response scale (e.g., predicted probabilities binomial models). verbose logical; whether display text progress bar indicating progress estimated time remaining procedure. Default TRUE. cl cluster object created parallel::makeCluster(), integer indicate number child-processes (integer values ignored Windows) parallel evaluations. See pbapply::pblapply() details. NULL, parallelization take place. ... sim_setx(), additional arguments passed marginaleffects::get_predict() (eventually predict()) compute predictions. print(), ignored. digits minimum number significant digits used; passed print.data.frame(). max.ests maximum number estimates display.","code":""},{"path":"/reference/sim_setx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute predictions and first differences at set values — sim_setx","text":"clarify_setx object, inherits clarify_est similar output sim_apply(), following additional attributes: \"setx\" - data frame containing values predictions made \"fd\" - whether first difference computed; set TRUE x1 specified FALSE otherwise","code":""},{"path":"/reference/sim_setx.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute predictions and first differences at set values — sim_setx","text":"x named list predictor values, crossed form reference grid marginal predictions. predictors set x assigned \"typical\" value, , factor, character, logical, binary variables mode, numeric variables mean, ordered variables median. values can seen \"setx\" attribute output object. x empty, prediction made point corresponding typical value every predictor. Estimates identified (summary(), etc.) variables differ across predictions. x1 supplied, first difference computed, considered difference two marginal predictions. One marginal prediction must specified x another, ideally single predictor changed, specified x1.","code":""},{"path":[]},{"path":"/reference/sim_setx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute predictions and first differences at set values — sim_setx","text":"","code":"data(\"lalonde\", package = \"MatchIt\")  fit <- lm(re78 ~ treat + age + educ + married + race + re74,           data = lalonde)  # Simulate coefficients set.seed(123) s <- sim(fit, n = 100)  # Predicted values at specified values of values, typical # values for other predictors est <- sim_setx(s, x = list(treat = 0:1,                             re74 = c(0, 10000)),                 verbose = FALSE) summary(est) #>                         Estimate 2.5 % 97.5 % #> treat = 0, re74 = 0         4771  3718   6078 #> treat = 1, re74 = 0         6389  4481   7983 #> treat = 0, re74 = 10000     8353  6713   9623 #> treat = 1, re74 = 10000     9971  8074  11796 plot(est)   # Predicted values at specified grid of values, typical # values for other predictors est <- sim_setx(s, x = list(age = c(20, 25, 30, 35),                             married = 0:1),                 verbose = FALSE) summary(est) #>                       Estimate 2.5 % 97.5 % #> age = 20, married = 0     6377  5096   7670 #> age = 25, married = 0     6395  5194   7624 #> age = 30, married = 0     6413  5296   7758 #> age = 35, married = 0     6431  5227   7912 #> age = 20, married = 1     7066  5577   8466 #> age = 25, married = 1     7084  5677   8166 #> age = 30, married = 1     7102  5834   8158 #> age = 35, married = 1     7120  5956   8354 plot(est)   # First differences of treat at specified value of # race, typical values for other predictors est <- sim_setx(s, x = data.frame(treat = 0, race = \"hispan\"),                 x1 = data.frame(treat = 1, race = \"hispan\"),                 verbose = FALSE) summary(est) #>           Estimate 2.5 % 97.5 % #> treat = 0     7054  5402   9382 #> treat = 1     8672  6416  11231 #> FD            1618  -193   3011 plot(est)"},{"path":"/reference/summary.clarify_est.html","id":null,"dir":"Reference","previous_headings":"","what":"Plotting and inference for clarify_est objects — plot.clarify_est","title":"Plotting and inference for clarify_est objects — plot.clarify_est","text":"summary() tabulates estimates confidence intervals (optionally) p-values clarify_est object. confint() computes confidence intervals. plot() plots \"posterior\" distribution estimates.","code":""},{"path":"/reference/summary.clarify_est.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plotting and inference for clarify_est objects — plot.clarify_est","text":"","code":"# S3 method for class 'clarify_est' plot(   x,   parm,   ci = TRUE,   level = 0.95,   method = \"quantile\",   reference = FALSE,   ncol = 3L,   simultaneous = FALSE,   ... )  # S3 method for class 'clarify_est' summary(   object,   parm,   level = 0.95,   method = \"quantile\",   null = NA,   simultaneous = FALSE,   ... )  # S3 method for class 'clarify_est' confint(   object,   parm,   level = 0.95,   method = \"quantile\",   simultaneous = FALSE,   ... )"},{"path":"/reference/summary.clarify_est.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plotting and inference for clarify_est objects — plot.clarify_est","text":"parm vector names indices estimates plot. unspecified, estimates displayed. ci logical; whether display confidence interval limits estimates. Default TRUE. level confidence level desired. Default .95 95% confidence intervals. method method used compute p-values confidence intervals. Can \"wald\" use Normal approximation \"quantile\" use simulated sampling distribution (default). See Details. Abbreviations allowed. reference logical; whether overlay normal density reference distribution plots. Default FALSE. ncol number columns used wrapping multiple plots; default 3. simultaneous logical; whether confidence intervals p-values simultaneous (.e., adjusted multiple comparisons); default FALSE. See Details. ... plot(), arguments passed ggplot2::geom_density(). object, x clarify_est object; output call sim_apply() wrappers. null values parameters null hypothesis p-value calculations. length equal number quantities estimated, one, case recycled, can named vector just names quantities null values set. Set values NA omit p-values quantities. values NA, default, p-values produced.","code":""},{"path":"/reference/summary.clarify_est.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plotting and inference for clarify_est objects — plot.clarify_est","text":"summary(), summary.clarify_est object, matrix containing coefficient estimates, standard errors, test statistics, p-values, confidence intervals. columns present depending arguments supplied summary(). confint(), matrix containing confidence intervals requested quantities. plot(), ggplot object.","code":""},{"path":"/reference/summary.clarify_est.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plotting and inference for clarify_est objects — plot.clarify_est","text":"summary() uses estimates computed original model estimates uses simulated parameters inference , line recommendations Rainey (2023). method = \"wald\", standard deviation simulation estimates used standard error, used z-statistics confidence intervals. p-values confidence intervals valid sampling distribution resulting statistic normal (can assessed using plot()). method = \"quantile\", confidence interval calculated using quantiles simulation estimates corresponding level, p-value calculated twice proportion simulation estimates less greater null, whichever smaller; equivalent inverting confidence interval truly valid true sampling distribution location shift sampling distribution null hypothesis therefore interpreted caution. Using \"method = \"quantile\" (default) recommended confidence intervals valid even sampling distribution Normally distributed. precision p-values confidence intervals depends number simulations requested (value n supplied sim()). simultaneous = TRUE, confidence intervals p-values adjusted account multiple comparisons using \"sup-t\" confidence region inversion. sup-t confidence region smallest rectangular region ensures simultaneous coverage parameters desired confidence level. found adjusting nominal confidence level new level found , simultaneously applied estimates, yields intervals contain estimates rates equal original level. Unlike adjustments multiple comparisons (e.g., Holm, Bonferroni, Benjamini-Hochberg), method takes account joint distribution estimates, often yielding narrower regions less conservative (still valid). P-values found finding level narrowest band guarantees simultaneous coverage containing null value given parameter. method = \"quantile\", Bayesian algorithm described Montiel Olea Plagborg-Møller (2019) used simulated estimates; method = \"wald\", new simulation performed treating estimates coming multivariate normal distribution. plots produced using ggplot2::geom_density() can customized ggplot2 functions. reference = TRUE, reference Normal distribution produced using empirical mean standard deviation simulated values. blue references line plotted median simulated values. Wald-based inference valid, reference distribution overlap empirical distribution, case quantile-based Wald-based intervals similar. quantile-based inference valid, median estimates overlap estimated value; necessary sufficient condition, though.","code":""},{"path":"/reference/summary.clarify_est.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plotting and inference for clarify_est objects — plot.clarify_est","text":"Montiel Olea, J. L., & Plagborg-Møller, M. (2019). Simultaneous confidence bands: Theory, implementation, application SVARs. Journal Applied Econometrics, 34(1), 1–17. doi:10.1002/jae.2656 Rainey, C. (2023). careful consideration CLARIFY: Simulation-induced bias point estimates quantities interest. Political Science Research Methods, 1–10. doi:10.1017/psrm.2023.8","code":""},{"path":[]},{"path":"/reference/summary.clarify_est.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plotting and inference for clarify_est objects — plot.clarify_est","text":"","code":"data(\"lalonde\", package = \"MatchIt\") fit <- glm(I(re78 > 0) ~ treat + age + race + nodegree + re74,           data = lalonde)  s <- sim(fit, n = 100)  # Compute average marginal means for `treat` est <- sim_ame(s, var = \"treat\", verbose = FALSE) coef(est) #>   E[Y(0)]   E[Y(1)]  #> 0.7453346 0.8175754   # Compute average marginal effects on risk difference # (RD) and risk ratio (RR) scale est <- transform(est,                  RD = `E[Y(1)]` - `E[Y(0)]`,                  RR = `E[Y(1)]` / `E[Y(0)]`)  # Compute confidence intervals and p-values, # using given null values for computing p-values summary(est, null = c(`RD` = 0, `RR` = 1)) #>         Estimate   2.5 %  97.5 % P-value #> E[Y(0)]   0.7453  0.6947  0.8243       . #> E[Y(1)]   0.8176  0.7340  0.9035       . #> RD        0.0722 -0.0345  0.1791    0.16 #> RR        1.0969  0.9569  1.2478    0.16  # Same tests using normal approximation and alternate # syntax for `null` summary(est, null = c(NA, NA, 0, 1),         normal = TRUE) #>         Estimate   2.5 %  97.5 % P-value #> E[Y(0)]   0.7453  0.6947  0.8243       . #> E[Y(1)]   0.8176  0.7340  0.9035       . #> RD        0.0722 -0.0345  0.1791    0.16 #> RR        1.0969  0.9569  1.2478    0.16  # Plot the RD and RR with a reference distribution plot(est, parm = c(\"RD\", \"RR\"), reference = TRUE,      ci = FALSE)   # Plot the RD and RR with quantile confidence bounds plot(est, parm = c(\"RD\", \"RR\"), ci = TRUE)"},{"path":"/reference/transform.clarify_est.html","id":null,"dir":"Reference","previous_headings":"","what":"Transform and combine clarify_est objects — transform.clarify_est","title":"Transform and combine clarify_est objects — transform.clarify_est","text":"transform() modifies clarify_est object allowing calculation new quantities existing quantities without re-simulating . cbind() binds two clarify_est objects together.","code":""},{"path":"/reference/transform.clarify_est.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transform and combine clarify_est objects — transform.clarify_est","text":"","code":"# S3 method for class 'clarify_est' transform(`_data`, ...)  # S3 method for class 'clarify_est' cbind(..., deparse.level = 1)"},{"path":"/reference/transform.clarify_est.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transform and combine clarify_est objects — transform.clarify_est","text":"_data clarify_est object transformed. ... transform(), arguments form name = value, name name new quantity computed value expression function existing quantities corresponding new quantity computed. See Details. cbind(), clarify_est objects combined. deparse.level ignored.","code":""},{"path":"/reference/transform.clarify_est.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Transform and combine clarify_est objects — transform.clarify_est","text":"clarify_est object, either new columns added (using transform()) combining two clarify_est objects. Note type attributes corresponding sim_apply() wrapper used (e.g., sim_ame()) lost using either function. can affect helper functions (e.g., plot()) designed work output specific wrappers.","code":""},{"path":"/reference/transform.clarify_est.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Transform and combine clarify_est objects — transform.clarify_est","text":"transform(), expression right side = use names existing quantities (e.g., `E[Y(1)]` - `E[Y(1)]`), ` appropriately included quantity name include parentheses brackets. Alternatively, can use indexes prefixed .b, e.g., .b2 - .b1, refer corresponding quantity position. can aid computing derived quantities quantities complicated names. (Note quantity named something like .b1, need referred position rather name, position-based label takes precedence). See examples. Setting existing value NULL remove quantity object. cbind() rename quantities check uniqueness names, important rename prior combining objects.","code":""},{"path":[]},{"path":"/reference/transform.clarify_est.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Transform and combine clarify_est objects — transform.clarify_est","text":"","code":"data(\"lalonde\", package = \"MatchIt\")  # Fit the model fit <- lm(re78 ~ treat * (age + educ + race +              married + re74 + re75),            data = lalonde)  # Simulate coefficients set.seed(123) s <- sim(fit, n = 100)  # Average adjusted predictions for `treat` within # subsets of `race` est_b <- sim_ame(s, var = \"treat\", verbose = FALSE,                  subset = race == \"black\") est_b #> A `clarify_est` object (from `sim_ame()`) #>  - Average adjusted predictions for `treat` #>  - 100 simulated values #>  - 2 quantities estimated:              #>  E[Y(0)] 4589 #>  E[Y(1)] 6148  est_h <- sim_ame(s, var = \"treat\", verbose = FALSE,                  subset = race == \"hispan\") est_h #> A `clarify_est` object (from `sim_ame()`) #>  - Average adjusted predictions for `treat` #>  - 100 simulated values #>  - 2 quantities estimated:              #>  E[Y(0)] 7015 #>  E[Y(1)] 7183  # Compute differences between adjusted predictions est_b <- transform(est_b,                    diff = `E[Y(1)]` - `E[Y(0)]`) est_b #> A `clarify_est` object (from `sim_apply()`) #>  - 100 simulated values #>  - 3 quantities estimated:              #>  E[Y(0)] 4589 #>  E[Y(1)] 6148 #>  diff    1559  est_h <- transform(est_h,                    diff = `E[Y(1)]` - `E[Y(0)]`) est_h #> A `clarify_est` object (from `sim_apply()`) #>  - 100 simulated values #>  - 3 quantities estimated:              #>  E[Y(0)] 7015 #>  E[Y(1)] 7183 #>  diff     169  # Bind estimates together after renaming names(est_b) <- paste0(names(est_b), \"_b\") names(est_h) <- paste0(names(est_h), \"_h\")  est <- cbind(est_b, est_h) est #> A `clarify_est` object (from `sim_apply()`) #>  - 100 simulated values #>  - 6 quantities estimated:                #>  E[Y(0)]_b 4589 #>  E[Y(1)]_b 6148 #>  diff_b    1559 #>  E[Y(0)]_h 7015 #>  E[Y(1)]_h 7183 #>  diff_h     169  # Compute difference in race-specific differences est <- transform(est,                  `diff-diff` = .b6 - .b3)  summary(est,         parm = c(\"diff_b\", \"diff_h\", \"diff-diff\")) #>           Estimate 2.5 % 97.5 % #> diff_b        1559  -632   3475 #> diff_h         169 -4730   4765 #> diff-diff    -1390 -5503   3817  # Remove last quantity by using `NULL` transform(est, `diff-diff` = NULL) #> A `clarify_est` object (from `sim_apply()`) #>  - 100 simulated values #>  - 6 quantities estimated:                #>  E[Y(0)]_b 4589 #>  E[Y(1)]_b 6148 #>  diff_b    1559 #>  E[Y(0)]_h 7015 #>  E[Y(1)]_h 7183 #>  diff_h     169"},{"path":"/news/index.html","id":"clarify-022","dir":"Changelog","previous_headings":"","what":"clarify 0.2.2","title":"clarify 0.2.2","text":"Simultaneous confidence bands p-values now available setting simultaneous = TRUE calls summary() plot(). sim_setx(), sim_ame(), sim_adrf() now accept arguments passed ..., passed marginaleffects::get_predict() compute predictions. Fixed bug using sim_ame() misim() specified. Thanks Arvind Ilamaran pointing bug. Added references published article R Journal, including package citation (citation(\"clarify\")). Fixed issue sampling t-distribution used slightly incorrect covariance matrix, leading intervals tiny bit wide small samples. Now using new random number generator tolerant nearly singular covariance matrices. removes dependence mvnfast. Results prior versions clarify reproducible using future versions, even using seed. Documentation updates. Error warning messages wrapped nicely.","code":""},{"path":"/news/index.html","id":"clarify-021","dir":"Changelog","previous_headings":"","what":"clarify 0.2.1","title":"clarify 0.2.1","text":"CRAN release: 2024-05-30 sim_ame() sim_adrf(), unit-level weights longer used compute means, consistent advice Gabriel et al. (2023). using functions matching weighting ATT ATC, change results. matching weighting ATE, improves robustness misspecified weights. sim_ame(), one variable can supplied var generate average adjusted predictions compute average marginal effects variables set supplied values. help page sim_ame() retooled reflect . transform(), values can now indicated positional shortcuts form .b{#}, e.g., .b1 - .b2, facilitate specifying transformations desired quantities without using names quantities, can frustrating use. reference = TRUE plot(), blue line median simulated estimates also included plot; value align estimate, quantile confidence intervals may invalid.","code":""},{"path":"/news/index.html","id":"clarify-020","dir":"Changelog","previous_headings":"","what":"clarify 0.2.0","title":"clarify 0.2.0","text":"CRAN release: 2023-09-21 sim_ame() sim_adrf() now argument, can used estimate quantities interest within subsets one variables. sim_setx() can now receive data frame x x1 arguments. sim_ame() can accept new options contrast: \"sr\" survival ratio \"srr\" switch relative risk. Slight speed improvements sim_ame() continuous var sim_adrf() contrast = \"amef\". Typo fixes vignettes.","code":""},{"path":"/news/index.html","id":"clarify-013","dir":"Changelog","previous_headings":"","what":"clarify 0.1.3","title":"clarify 0.1.3","text":"CRAN release: 2023-05-04 Documentation updates incorporating work Rainey (2023). clarify already implemented recommendations Rainey (2023) functionality changed.","code":""},{"path":"/news/index.html","id":"clarify-012","dir":"Changelog","previous_headings":"","what":"clarify 0.1.2","title":"clarify 0.1.2","text":"CRAN release: 2023-02-22 Added argument reference plot.clarify_est(), adds reference normal distribution density estimates. Fixed error sim() documentation degrees freedom computed. Thanks @wviechtb. (#8) Fixed warning can occur recovering model data, insight.","code":""},{"path":"/news/index.html","id":"clarify-011","dir":"Changelog","previous_headings":"","what":"clarify 0.1.1","title":"clarify 0.1.1","text":"CRAN release: 2023-02-03 summary.clarify_est(), null can now supplied named vector specify quantities p-values computed. Fixes anticipation breaking changes marginaleffects ensure compatibility (including older versions). Updates README vignettes.","code":""},{"path":"/news/index.html","id":"clarify-010","dir":"Changelog","previous_headings":"","what":"clarify 0.1.0","title":"clarify 0.1.0","text":"CRAN release: 2023-01-25 First release!","code":""}]
